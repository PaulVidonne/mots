#!/bin/bash

version="6.30 b-210402"

# pour debug
# set -x
# date
# file="tmp`date +%H%M%S`"
# cp $0 $file
# fin pour debug


if [ ! -t 0 ]; then
   type_entree=pipee    # entrée des données par pipe "|" ou redirection "<"
else
   type_entree=directe  # entrée des données par fichier désigné dans la ligne de commnade
fi

#-------------------------------------test entrée directe------------------------------------
if [ $type_entree == directe ];then
   if [ $# -lt 1 ];then
      echo -e "\n::: Usage : $(basename $0) [--help | --version] [OPTIONS]... FICHIER | redirection"
      echo -e "::: Le fichier à analyser n'est pas indiqué\n"
      exit
   fi
   if [ $1 == --version ] ;then
      echo -e "\n::: $(basename $0) version : $version\n"
      exit
   fi
#-------------------------------------dont le help-------------------------------------------
echo $@ | grep -q -E "\-\-help"
if [ $? == 0 ] ; then
echo -e "\n\e[1;97mPRESENTATION GENERALE\e[0m"
cat << EOF

   Usage     $(basename $0) [--help | --version] [OPTIONS]... FICHIER | redirection

   Objet     le logiciel $(basename $0) version $version décompte les mots, les syllabes, les phrases
             et les caractères d'un texte ou d'une liste ; il calcule la longueur des mots et des
             phrases et fait leurs moyennes. Il calcule la fréquence des caractères et des mots, avec
             de nombreuses possibilités : il permet par exemple de rechercher la fréquence des mots
             d'un vocabulaire donné ou d'une longueur donnée. Il calcule tous les indices classiques
             de lisibilité auxquels il ajoute un indice spécifique. Il calcule trois indicateurs de
             richesse de vocabulaire. Il comprend de nombreuses options et sous-options. Il restitue
             les données de manière détaillée ou synthétique à l'écran ou dans un fichier de type
             texte ou PDF. Il peut établir un fichier de sortie au format CSV pour retraitements
             externes.
EOF
echo -e "\n\e[1;97mOPTIONS ET SOUS-OPTIONS\e[0m"
cat << EOF

   --help    la présente aide
   --version version

   ANALYSE DES MOTS
             sans arguments, '$(basename $0)' affiche la synthèse de l'analyse du texte soumis, avec les
             longueurs moyennes des mots et des phrases (pour les textes), le nombre de phrases,
             de mots, de lignes, de caractères et calcule les trois indices de lisibilité de
             Coleman-Liau, ARI et un indice spécifique, sans lister les mots du texte.

      -l     fait de même et liste des mots avec leur longueur individuelle et leur rang dans l'ordre
             du texte et donne la répartition des mots selon leur taille en nombre de lettres.

      -s     liste les mots décomposés en syllabes, les décompte, indique la répartition des mots
             par nombre de syllabes et ajoute les quatre indices de lisibilité de Flesh-Kincaid
             général, Flesh-Kincaid éducation, Gunning-Fog et SMOG. L'usage de l'option -s0 est
             suggéré.

   FREQUENCE DES CARACTERES
             les deux options ci-après établissent la fréquence des caractères du texte analysé
             avec le pourcentage que représente chacun (hors espaces).

      -ca    liste les caractères du texte avec leur fréquence dans l'ordre alphabétique. Cet
             ordre peut varier avec les langues et les distributions de bash et du système
             d'exploitation.

      -cf    liste les caractères du texte avec leur rang et leur fréquence dans l'ordre de leur
             fréquence.

   FREQUENCE DES MOTS
             toutes les options ci-après calculent la fréquence des mots et les quatre indices
             de dispersion du vocabulaire de Gini, Gini hors happax, Shannon et Simpson. L'usage
             de l'option -sc est suggéré.

      -fa    liste les mots du texte avec leur fréquence dans l'ordre alphabétique. Cet ordre
             peut varier avec les langues et les distributions de bash et du système
             d'exploitation.

      -ff    liste les mots du texte avec leur rang et leur fréquence dans l'ordre de leur
             fréquence.

      -xa    liste les mots du texte, déterminé par les sous-options -x=XXX et -y=YY, avec leur
             fréquence dans l'ordre alphabétique.

      -xf    liste les mots du texte, déterminé par les sous-options -x=XXX et -y=YY, avec leur
             rang et leur fréquence dans l'ordre de leur fréquence.

      -x=XXX liste les XXX premières fréquences des mots du texte analysé. Maximum 999999. Par
             défaut XXX=20. Toujours associé à une valeur de YY.

      -y=YY  liste les fréquences des mots du texte analysé de plus de YY caractères. Par défaut
             YY=3. Minimum 1. Maximum 14. Toujours associé à une valeur de XXX.

      -i=FICHIER
             FICHIER est un fichier de vocabulaire qui contient les mots dont on recherche la
             fréquence dans le texte analysé. Le séparateur des mots dans FICHIER est l'espace.
             Ces mots peuvent comprendre apostrophe, tiret, tiret inférieur, barre oblique,
             espace insécable ainsi que point et virgule pour les nombres. Tout autre signe est
             ignoré (notamment les glyphes monétaires). Pas de joker possible. Option -ia ou -if
             obligatoire.

      -ia    liste les mots du texte présents dans le fichier de vocabulaire défini par
             -i=FICHIER avec leur fréquence dans l'ordre alphabétique.

      -if    liste les mots du texte présents dans le fichier de vocabulaire avec leur rang et
             leur fréquence dans l'ordre de leur fréquence.

      -isc   remplace les capitales par des bas de casse dans le fichier de vocabulaire.

      -isd   remplace les caractères avec signes diacritiques par les mêmes sans signes
             diacritiques dans le fichier de vocabulaire.

      -is0   supprime les chiffres (0 à 9) dans le fichier de vocabulaire.

   REGROUPEMENT D'OPTIONS

      -z    regroupe les options -s -fa -sl de sorte que toutes les données et tous les indices
            sont affichés de manière synthétique par une seule commande.

   SOUS-OPTIONS GENERALES
             les sous-options générales s'appliquent aux analyses des mots et à celles des
             fréquences pour les textes seulement (sauf -sc et -sd qui peuvent s'appliquer aux
             listes).

      -m     remplace les espaces des expressions monétaires numériques exprimées par groupes de
             trois chiffres par des espaces insécables, de sorte que ces expressions deviennent
             des mots.

      -sc    remplace les capitales par des bas de casse dans les données analysées.

      -sd    remplace les caractères avec signes diacritiques par les mêmes sans signes
             diacritiques.

      -sp    supprime la "ponctuation" (en fait tous les "autres caractères imprimables" dont la
             liste figure ci-dessous).

      -s0    supprime les chiffres (de 0 à 9) des données analysées. Entraine la suppression des
             signes situés entre les chiffres et des glyphes pouvant les suivre.

      -sl    annule l'impression détaillée des listes et n'affiche que la synthèse des analyses.

      -c=CHARSET
             charset du fichier à analyser forcé à CHARSET et non à la valeur décelée par le
             programme.

      -o=FICHIER
             envoie le résultat écran également dans le fichier FICHIER. Le crée s'il n'existe pas.

      -pdf   réalise une copie du fichier FICHIER au format PDF ; ce fichier prend le nom de
             FICHIER avec l'extension .pdf

      -csv   réalise une copie des données numériques du fichier FICHIER au format CSV pour
             traitements mathématiques ou graphiques externes (loi de Zipf par exemple).
             Séparateur de champs  ";" chaînes encadrées par des doubles quotes. Ce fichier
             prend le nom de FICHIER avec l'extension .csv

      -?     les options non listées ci-dessus sont ignorées.

   VERIFICATION

      -v     valide les chiffres donnés par vérification de la concordance entre les résultats
             de l'analyse des mots et de celle des caractères.

EOF
echo -e "\e[1;97mDEFINITIONS\e[0m"
cat << EOF

   DEFINITIONS GENERALES

      fichier
             tout fichier informatique (a priori composé de texte), pour tout charset. Le
             logiciel vérifiera le type et écartera les fichiers non exploitables : binaires,
             fichiers au format traitement de texte en particulier. Si plusieurs noms de fichiers
             sont indiqués, seul le dernier sera pris en compte.

      liste  est considérée comme liste toute suite de caractères et de signes divers figurant
             sur une ligne distincte. Chaque ligne est considérée comme formant un seul mot,
             l'auteur étant seul responsable de ce qu'il considère comme tel. Aucun traitement
             automatique n'est effectué sur les listes. Seules les options -sc -sd peuvent leur
             être appliquées.

      texte  texte quelconque pouvant comprendre tous les signes figurant ou pouvant être
             composés sur les différents claviers latins nationaux.

      type   liste ou texte. Type déterminé par le logiciel selon le critère suivant : une
             liste comprend moins d'espaces sécables que de lignes.

      mot    EN LISTE. Toute suite de caractères figurant sur une même ligne, par exemple "eau
             de vie" sans tirets est considéré comme un seul mot. Tout autre signe figurant
             sur la ligne est compté dans la longueur du mot, y compris les éventuelles espaces
             finales.

             EN TEXTE. Toute suite continue de caractères alphabétiques ou numériques séparée
             par une espace sécable. Ainsi "eau de vie" sans tirets sera considéré comme trois
             mots, sauf si les espaces sont des insécables. Les mots comportant apostrophe,
             tiret, tiret inférieur, barre oblique, espace insécable, point forment un seul mot
             comme "arc-en-ciel", "aujourd’hui", "O'Connor", "10/18" ou "www.societe.com". Ces
             règles sont ici étendues aux nombres, considérés comme des mots, qui peuvent
             comprendre, en outre, virgule et signe degré, comme dans "6,35" ou "37°2". De plus,
             les nombres suivis, avec ou sans espace sécable, des signes "%, ‰" ou d'un des
             glyphes monétaires "€, £, ¥ ou $" sont considérés comme un seul mot.

      vocabulaire
             ensemble des mots présents une ou plusieurs fois dans le texte. Cet ensemble
             correspond à la 'richesse spécifique' des études de diversité. Aucun regroupement
             n'est effectué : ainsi, tous les mots issus d'une même racine (conjugaison par
             exemple) constituent autant de mots uniques différents constitutifs du vocabulaire.

      phrase
             ensemble de signes se terminant par un point, un point d'interrogation ou un point
             d'exclamation suivi d'une espace ou situé en fin de ligne.

      syllabe
             mot court ou partie de mot comprenant au moins une voyelle.

      autres caractères imprimables
             tout signe imprimable, autre que chiffres et lettres, apostrophe, tiret, tiret
             inférieur, barre oblique, espace insécable et point internes aux mots, point et
             virgule internes aux nombres, signes "%, ‰" et glyphes monétaires quand ils suivent
             un nombre. Il en résulte qu'un signe orphelin (supposons "%") sera considéré comme
             un "autre" alors qu'il composera un nom s'il suit un chiffre. La liste des autres
             caractères ne comprend que les plus utilisés. Il en existe des milliers d'autres
             qui apparaîtront alors comme autant de mots. La liste actuelle comprend les 71
             suivants ! " # % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ \` { | } ~ ¡ § « ° »
             ¿ × ÷ – ’ “ ” ‰ − $ £ € ½ ¼ ʾ µ … · ² ³ ® ± ´ º ¥ © ¨ ¾ ¹ ¸ ª ¦ ¶ ¤ ¢

      charset
            jeu de caractères, de l'anglais "character set", façon de représenter de manière
            informatique une liste donnée de caractères. Ici, le charset du fichier original est
            détecté par le logiciel (sauf si -c=CHARSET est défini) et converti ensuite en
            utf-8 pour traitements. Le charset 437 est attribué par défaut aux charsets non
            reconnus. Il est parfois utile de le forcer à une autre valeur.

      ligne vide
            vide au sens visuel. Peut en réalité comprendre ou non des espaces.

      hapax
             mot ne présentant qu'une seule occurence dans le texte analysé.

   INDICES DE LISIBILITE
             Les indices de lisibilité sont les indices classiques auxquels s'ajoute un indice
             spécifique. Ils sont toujours calculés avec leur formule canonique, mais à partir
             de nombres de mots, syllabes et phrases qui respectent nos propres conventions. Les
             éventuelles réserves sont exprimées ci-après. Les indices 'syllabiques' exigent
             l'option -s qui demande un temps de calcul plus élevé que les indices non-syllabiques.
             Ces derniers reposent sur la seule longueur des mots et des phrases, tandis que les
             premiers font appel en outre au nombre de syllabes. Les linguistes anglo-saxons font
             la correspondance entre ces indices et le niveau d'éducation (grade level).

      indice spécifique
             indice non syllabique. Le résultat va de 4 pour un niveau CP à plus de 18 pour
             'Le Discours de la Méthode'. Sa formule  est la suivante : longueur moyenne des
             mots moins 4,2 plus sept fois le logarithme népérien de la longueur moyenne des
             phrases moins 8 le tout divisé par 1,3.

      indice de Coleman-Liau
             indice non syllabique dû à Meri Coleman et T.L. Liau.

      indice ARI (Automated Readability Index)
             indice non syllabique. Provient de l'armée américaine dans les années 60. Destiné
             à s'assurer de la lisibilité des textes dactylographiés

      indice de Flesh-Kincaid général
             indice syllabique dû à Rudolf Flesh et Peter Kincaid. La libilité est d'autant
             plus grande que l'indice est élevé. L'indice 0 dénote un texte compliqué, 60 à
             80 un texte lisible pour des 12-15 ans. Mais cet indice peut prendre des valeurs
             extrêmes ou devenir négatif.

      indice éducation de Flesh-Kincaid
             indice syllabique, dû aux mêmes. Le niveau de cet indice est censé indiquer
             le niveau d'étude nécessaire pour lire correctement un texte. Peut en réalité
             prendre des valeurs qui dépassent nettement les niveaux d'éducation.

      indice de Gunning-Fog
             indice syllabique, dû à Robert Gunning. Le texte doit être débarassé des noms
             propres, du jargon, des mots composés, ce qui n'est pas le cas ici. Va de 8-9
             pour des textes de juniors ou adolescents à 17-18 pour des articles universi-
             taires. L'indice est calculé ici sur la totalité du texte et non sur un extrait.

      indice SMOG
             indice syllabique dû à G. Harry McLaughlin. Utilisé ici dans sa formule canonique,
             mais repose sur la totalité du texte et non sur des extraits.

   INDICES DE DIVERSITE
             Les indices de diversité mesurent la richesse du vocabulaire employé. Ils proviennent
             tous d'autres champs scientifiques que celui de la linguistique (science économique,
             théorie de l'information et statistique).

      indice de Gini
             fonction mathématique, due à Corrado Gini, pour mesurer l'inégalité des revenus,
             adapté ici pour prendre en compte le poids des mots en fonction de leur fréquence.
             Afin de le rendre plus intuitif, il est inversé (1-G), 0 correspondant à une forte
             prépondérance des mots de grande fréquence, 1 à une égalité totale du poids de
             de tous les mots. Il varie donc dans le même sens que les indices de diversité de
             Shannon et Simpson, mais ne mesure pas la même chose. Une variante est ici adjointe
             en un indice hors happax.

      indice de Shannon
             fonction de mesure de l'entropie, due à Claude Shannon, à la base de la théorie de
             l'information. Pour rendre cet indice plus cohérent avec les autres, il est ici
             ramené de 0 à 1 (par division du résultat par le logarithme du vocabulaire). Dès
             lors, 0 correspond à une diversité nulle des mots, 1 à une diversité totale.

      indice de Simpson
             fonction statistique, due à Edward Simpson, relative aux tirages au hasard. Les
             'espèces' sont ici les mots du vocabulaire. Afin de rendre cet indice plus intuitif
             et cohérent avec les deux autres, c'est en fait l'indice de diversité de Simpson
             qui est ici représenté, 0 correspondant à une diversité nulle des mots, 1 à une
             diversité totale. Par rapport à l'indice de Shannon, il majore l'importance des
             mots de faible occurrence et notamment des happax.

EOF
echo -e "\e[1;97mAVERTISSEMENTS ET MISES EN GARDE\e[0m"
cat << EOF

      réserves générales
             le présent script est destiné à l'examen de fichiers textes en vue d'en quantifier
             les composants principaux que sont les mots, leur décomposition en syllabes, et
             les caractères. Il comporte des choix, qui peuvent être discutés. Il n'a nulle
             prétention à l'exhaustivité : son usage se limite aux alphabets des langues latines
             et aux textes plutôt littéraires. Il est moins opérant pour les textes comportant
             des signes propres à une discipline particulière. La plus grande liberté est laissée
             à l'usager, qui peut notamment cumuler tous les choix d'options. Ces options peuvent
             être spécifiées dans n'importe quel ordre. Si l'option --help est présente, elle
             l'emporte sur toutes les autres et sera la seule à être exécutée.

      option -s
             la mise en oeuvre de cette option entraîne des temps de traitement qui peuvent être
             assez longs pour les textes volumineux. Elle est nécessaire au calcul des indices 
             syllabiques.

      option -m
             l'activation de l'option -m regroupe tous les blocs de trois chiffres des
             expressions monétaires pour en faire un seul mot par remplacement des espaces
             simples par des insécables. Il en résulte une diminution du nombre d'espaces et de
             mots et une augmentation de la longueur de ces derniers. Le nombre de points et
             virgules inclus dans les mots est alors indiqué. Des effets indésirables peuvent se
             produire : des suites de chiffres qui ne sont pas des expressions monétaires
             peuvent être compactés (les expressions régulières ont des limites !). L'activation
             de l'option -l permet de connaître le résultat des traitements.

      options -sc et -sd
             tous les caractères latins sont reconnus (notamment ceux propres aux alphabets
             albanais, allemand, corse, espagnol, islandais, italien, norvégien, polonais,
             portugais, roumain, serbe, suédois et tchèque).

      option -i=FICHIER
             les composants du fichier FICHIER sont reconnus par le logiciel selon les règles
             qui prévalent à l'article mot ci-dessus. Les éventuels détritus sont éliminés.
             Attention, l'usage d'apostrophes différentes (' et ’) distinguent des mots
             différents.

      fréquences des caractères
             calculées hors espaces.

      interprétation des résultats
             l'interprétation des résultats pouvant surprendre qui n'a pas lu avec soin la
             présente aide, les espaces dans les listes sont remplacées par des tildes lors de
             l'affichage par -l. Le rapport du nombre de caractères, espaces, autres caractères
             au nombre d'octets n'est pas évident, un caractère pouvant correspondre à un, deux
             ou trois octets selon le charcet. Seul l'us-acii assure l'égalité du nombre d'octets
             et de caractères. wc peut faire apparaître un nombre de mots un peu supérieur, ce
             qui est normal compte tenu de la définition très extensive de ce qu'est un mot pour
             wc. Le rapprochement de la comptabilité en mots et en caractères peut être vérifié
             par l'option -v. L'algorithme de syllabation a été retenu en raison de sa simplicité,
             de sa modularité et de sa rapidité. Il ne cherche pas la perfection : par exemple
             les schwas ne sont pas éliminés, la coupure apparaît parfois décalée et le nombre
             de syllabes est parfois augmenté ou diminué d'une unité. Mais les erreurs se
             compensent et le nombre de syllabes apparaîtra acceptable aux yeux du statisticien.
             La syllabation retenue est propre à la langue et aux caractères français. Tous les
             résultats sont affichés au dix-millième mais sont calculés de manière plus précise.
             La correspondance entre le niveau d'éducation et les indices de lisibilité (tous
             d'origine anglo-saxonne) n'a qu'une valeur limitée. Elle est dépourvue de toute
             signification pour certains indices dans les cas limites. Les valeurs calculées par
             le présent script et par d'autres automates peuvent être plus ou moins différentes en
             raison des différences de définition des concepts et des méthodes utilisées.

      limites (volume, temps d'exécution)
             ce script fonctionne en principe sur tout système doté de l'interpréteur de commandes
             bash. Il permet de traiter des textes de grande taille. Sa vitesse et ses capacités
             d'exécution dépendent des ressources de l'ordinateur utilisé. Compter une à deux
             minutes par million de mots pour les analyses de mots et de caractères avec un CPU
             à 3.60 GHz. Le volume des fichiers traitables ne dépend que de la taille de la
             mémoire. Compter un peu plus de 1,7 Go de mémoire par million de mots. Testé pour des
             fichiers de 55 millions de mots. L'option -s est un peu longue ; le calcul du nombre
             de syllabes et des indices syllabiques demandent entre une et deux heures pour un
             roman de 150 000 mots. Les calculs de fréquences de mots et de caractères ne prennent
             que quelques minutes pour des textes de cette taille, mais ce temps augmente
             rapidement avec le volume des données à analyser.

      exécutabilité
             script réalisé sous GNU bash, version 5.0.17(1)-release-(x86_64-redhat-linux-gnu),
             en principe POSIX.

      bugs   merci de signaler bugs et suggestions à : paul at vidonne point fr

      licence
             Copyright (c) $(date +%Y) Paul Vidonne. Ce script peut être librement exécuté, diffusé et
             modifié dans les conditions de la 'Creative Commons Attribution-NonCommercial
             -ShareAlike 3.0 Unported License' (CC-BY-NC-SA) publiée par Creative Commons. Il
             est mis à disposition "tel quel", SANS AUCUNE GARANTIE de quelque nature que ce
             soit et auprès de qui que ce soit. Plus d'informations (en anglais) sur la licence
             à <https://creativecommons.org/licenses/by-nc-sa/3.0/>, dont le texte intégral se
             trouve à <https://creativecommons.org/licenses/by-nc-sa/3.0/legalcode>.

$(basename $0)                                        $version                                  ----
EOF
exit
fi # fin --help
fi # fin entree_directe

#fin tests entree directe------------entree des donnees-------------------------------------
if [ ! -t 0 ]; then
   donnees_brutes=$(cat | tr -d '\0'; echo x)
   donnees_brutes=${donnees_brutes%x}
   donnees_brutes=$(sed 's/.*\x0a$//g' <<< "$donnees_brutes")
   donnees_source="::: Données pipées : $(basename $0) "
   donnees_origine="de l'entrée pipée"
   ligne_commande=$@
   nb_arg_ligne_commande=$#
else
   # les donnees brutes ne peuvent etre saisie ici dans le désordre de la ligne de commande
   # donnees_brutes=$(cat $1) mais après réassignement ligne de commande
   donnees_source="::: Commande : $(basename $0) "
   ligne_commande=$@
   nb_arg_ligne_commande=$#
fi

#------------------------------------analyse de la ligne de commande-----------------------
# set -f ne s'applique pas au shell appellant, mais marche dans les fonctions !
# donc if -24 destiné a contrer la présence d'une * dans les arguments
if [ $nb_arg_ligne_commande -lt 24 ]; then
   analyse_chars=0
   analyse_frequence=0
   analyse_mots_detail=0
   lister_c_alpha=0
   lister_c_freq=0
   lister_f_alpha=0
   lister_f_freq=0
   lister_i_alpha=0
   lister_i_alpha_tmp=0
   lister_i_freq=0
   lister_m_texte=0
   lister_x_alpha=0
   lister_x_freq=0
   lister_liste=1
   nb_mots_xx=0
   option_fichier_fourni=0
   option_monetaire=0
   option_syllabeur=0
   option_csv=0
   option_pdf=0
   verification=0
   xxx_yyy=0
   xxx=20
   yyy=3

   for i in $ligne_commande ; do
      arg=$i
      if [ $i == "-l" ]; then
         analyse_mots_detail=1
         lister_m_texte=1
      elif [ $i == "-s" ]; then
         analyse_mots_detail=1
         option_syllabeur=1
      elif [ $i == "-ca" ]; then
         analyse_chars=1
         lister_c_alpha=1
      elif [ $i == "-cf" ]; then
         analyse_chars=1
         lister_c_freq=1
      elif [ $i == "-fa" ]; then
         analyse_frequence=1
         lister_f_alpha=1
      elif [ $i == "-ff" ]; then
         analyse_frequence=1
         lister_f_freq=1
      elif [ $i == "-xa" ]; then
         analyse_frequence=1
         lister_x_alpha=1
      elif [ $i == "-xf" ]; then
         analyse_frequence=1
         lister_x_freq=1
      elif [ $i == "-ia" ]; then
         analyse_frequence=1
         lister_i_alpha=1
      elif [ $i == "-if" ]; then
         analyse_frequence=1
         lister_i_freq=1
      elif [ $i == "-m" ]; then
         option_monetaire=1
      elif [ $i == "-sc" ]; then
         bas_de_casse=1
      elif [ $i == "-sd" ]; then
         diacritique=1
      elif [ $i == "-sp" ]; then
         supp_punct=1
      elif [ $i == "-s0" ]; then
         supp_chiffre=1
      elif [ $i == "-isc" ]; then
         bas_de_casse_i=1
      elif [ $i == "-isd" ]; then
         diacritique_i=1
      elif [ $i == "-is0" ]; then
         supp_chiffre_i=1
      elif [ $i == "-sl" ]; then
         lister_liste=0
      elif [ $i == "-z" ]; then
         analyse_mots_detail=1
         option_syllabeur=1
         analyse_frequence=1
         lister_f_alpha=1
         lister_liste=0
      elif [ $i == "-v" ]; then
         analyse_mots_detail=1
         analyse_chars=1
         verification=1
      elif [ ${arg:0:3} == "-i=" ]; then
         fichier_fourni=${arg:3:50}
         option_fichier_fourni=1
         if [ -d $fichier_fourni ] ; then
             echo -e "\n::: '$fichier_fourni' est un répertoire. Il faut indiquer un fichier. Abandon\n"
             exit
         fi
         if ! [ -f $fichier_fourni ] || ! [ -s $fichier_fourni ] ; then
             echo -e "\n::: Le fichier '$fichier_fourni' n'existe pas, ou il est vide. Abandon\n"
             exit
         fi
         if [ $(file -i $fichier_fourni | sed -e "s/.*charset=//") == "binary" ] ; then
             echo -e "\n:::le fichier $fichier_fourni est un fichier binaire. Abandon\n"
             exit
         fi
      elif [ ${arg:0:3} == "-o=" ]; then
         fichier_sortie=${arg:3:50}
         if [ -d $fichier_sortie ] ; then
             echo -e "\n::: '$fichier_sortie' est un répertoire. Il faut indiquer un fichier. Abandon\n"
            exit
         fi
         if [ -s $fichier_sortie ] ; then
             echo -e "\n::: Le fichier '$fichier_sortie' existe, mais il n'est pas vide. Abandon\n"
             exit
         fi
         if ! [ -f $fichier_sortie ] ; then
             echo -e "\n::: Le fichier '$fichier_sortie' n'existe pas, il est créée"
         elif ! [ -s $fichier_sortie ] ; then
             echo -e "\n::: Le fichier '$fichier_sortie' existe, il est vide et sera utilisé"
         fi
      elif [ ${arg:0:4} == "-csv" ] ; then
         option_csv=1
      elif [ ${arg:0:4} == "-pdf" ] ; then
         option_pdf=1
      elif [ ${arg:0:3} == "-x=" ]; then
         xxx=${arg:3:6}
         if ! [[ $xxx == +([0-9]) ]] ; then
             echo -e "\n::: L'expression $xxx n'est pas un nombre. Abandon\n"
             exit
         fi
         xxx_yyy=1
     elif [ ${arg:0:3} == "-y=" ]; then
         yyy=${arg:3:2}
         if ! [[ $yyy == +([0-9]) ]] ; then
             echo -e "\n::: L'expression $yyy n'est pas un nombre. Abandon\n"
             exit
         elif [ $yyy -gt 14 ]; then
             echo -e "\n::: L'expression -y=$yyy est ramenée à 14. On continue\n"
             yyy=14
         elif [ $yyy ==  0 ]; then
             echo -e "\n::: L'expression -y=$yyy n'est pas possible. Abandon\n"
             exit
         fi
         xxx_yyy=1
      elif [ ${arg:0:3} == "-c=" ]; then
         char_set=${arg:3:20}
         iconv -l | grep -i -e ^$char_set//$ 2>/dev/null
         if [ $? == 1 ] ; then
           echo -e "\n::: Le charset \"$char_set\" n'est pas reconnu. Abandon\n"
           exit
         fi
      elif [ ${arg:0:1} != "-" ]; then
         if [ $type_entree == pipee ]; then
            echo -e "\n::: argument ${arg:0:10} non valable dans la ligne de commande. Abandon\n"
             exit
         else
             set $i # on réassigne $1... un peu idiot, mais c'est comme ça
             donnees_origine="du fichier $1"
         fi
   fi # de tous les if elif
   done # i in ligne de commande

      if [[ $lister_i_alpha == "1" || $lister_i_freq == "1" ]] && [ -z $fichier_fourni ]; then
          echo -e "\n::: Pas de fichier défini par -i= . Abandon\n"
          exit
      fi
      if [[ $option_fichier_fourni == "1"  &&  $lister_i_alpha == "0" && $lister_i_freq == "0" ]] ; then
         echo -e "\n::: Avec un fichier fourni il faut préciser -ia ou -if. Abandon\n"
         exit
      fi
      if [ $xxx_yyy == 1 ] && [ $lister_x_alpha == 0 ] && [ $lister_x_freq == 0 ] ; then
         echo -e "\n::: Il faut accompagner -x=XXX ou -y=YY de -xa et/ou -xf. Abandon\n"
         exit
      fi
      if [[ $option_monetaire == "1"  &&  $supp_chiffre == "1" ]] ; then
         echo -e "\n::: Les deux options -m et -sc sont contradictoires. Abandon\n"
         exit
      fi
      if [ $option_csv == 1 ] ; then
         if [ "$fichier_sortie" == "" ] ; then
            echo -e "\n::: Il faut un fichier de sortie (option -o=) pour obtenir un csv. Abandon\n"
            exit
         fi
         if [ -s $fichier_sortie.csv ] ; then
            echo -e "\n::: Le fichier '$fichier_sortie.csv' existe mais il n'est pas vide. Abandon\n"
            exit
         fi
         if [ $lister_liste == 0 ] ; then
            echo -e "\n::: Le fichier '$fichier_sortie.csv' serait vide compte tenu de l'option -sl. Abandon\n"
            exit
         fi
      fi
      if [ $option_pdf == 1 ] ; then
         if [ "$fichier_sortie" == "" ] ; then
            echo -e "\n::: Il faut un fichier de sortie (option -o=) pour obtenir un pdf. Abandon\n"
            exit
         fi
         if [ -s $fichier_sortie.pdf ] ; then
            echo -e "\n::: Le fichier '$fichier_sortie.pdf' existe mais il n'est pas vide. Abandon\n"
            exit
         fi
      fi
      # etablissement de l'analyse par defaut
      if [ "$analyse_mots_detail" != "1" -a "$analyse_chars" != "1" -a "$analyse_frequence" != "1" ];then
        analyse_mots_detail=1
        analyse_chars=0
        analyse_frequence=0
      fi
      if [ ! $fichier_sortie ] ; then
         fichier_sortie=/dev/null
      fi
      jour=$(date)
      echo -e "\n::: Le $jour" | tee -a $fichier_sortie
      echo -e "::: Programme : $0 version $version" | tee -a $fichier_sortie
      if [ $type_entree == directe ];then
         echo -e "::: Analyse fichier : $ligne_commande " | tee -a $fichier_sortie
      else
         echo -e "::: Analyse flux pipé : $ligne_commande " | tee -a $fichier_sortie
      fi
else
   echo -e "\n::: Trop d'arguments après $0 ('*'?). Abandon\n"
   exit
fi # fin nb arg ligne cmd inf à 15

# fin analyse ligne cmd--------------si direct test fichier à analyser----------------------
if [ $type_entree == directe ]; then # on teste le fichier a analyser
   if [ $# -lt 1 ] || [ ${1:0:1} == "-" ] ; then
      echo -e "\n::: Usage : $(basename $0) [--help | --version] [OPTIONS]... FICHIER | redirection"
      echo -e "::: Le fichier à analyser n'est pas indiqué\n"
      exit
   fi
   if ! [ -f $1 ] ; then
      echo -e "\n::: Usage : $(basename $0) [--help | --version] [OPTIONS]... FICHIER | redirection"
      echo -e "::: Le fichier $1 n'existe pas. Abandon\n"
      exit
   fi
   if ! [ -s $1 ] ; then
      echo -e "\n::: Usage : $(basename $0) [--help | --version] [OPTIONS]... FICHIER | redirection"
      echo -e "::: Le fichier $1 est vide. Abandon\n"
      exit
   fi
   if [ "$char_set" == "" ] ; then
      char_set=$(file -i "$1" | sed -e "s/.*charset=//")
   fi
   if [ "$char_set" == "unknown-8bit" ]; then
       char_set=437
   fi
   if [ "$char_set" == "binary" ]; then
      echo -e "\n::: le fichier $1 est un fichier binaire. Pas d'exploitation\n"
      exit
   fi
fi # fin entree directe

# avec entrée directe on peut enfin affecter donnees brutes, après réassignement et vérif ci-dessus
if [ -t 0 ]; then
    donnees_brutes=$(cat $1)
fi

# fin test fichier analyse direct----test flux données si entree pipée----------------------
if [ $type_entree == pipee ]; then
   if [ ${#donnees_brutes} -eq 0 ];then
      echo -e "\n::: Le flux d'entrée est vide. Abandon\n"
      exit
   fi
   if [ "$char_set" == "" ] ; then
       char_set=$(echo $donnees_brutes | file -i - | sed -e "s/.*charset=//")
   fi
   if [ "$char_set" == "binary" ]; then
      echo -e "\n::: le flux de données est binaire. Pas d'exploitation\n"
      exit
   fi
fi # avec dans les deux cas
if [ "$char_set" == "unknown-8bit" ]; then
    char_set=437
fi

# fin test flux données--------------rappels ------------------------------------------------

# \xe2\x80\x93 = demi quadratin
# \xc2\xa0 = insécable
# \xe2\x80\xaf = insécable fine
# (\x08 \b BS) - (\x09 \t HT) - (\x0a \n LF) - (\x0b \v VT)
# (\x0c \f FF) - (\x0d \r CR) - (\c supprime le \n)

# fin rappels -----------------------fonction : préliminaire--------------------------------
preliminaire()
{
   pleines=$(grep -v -c -E "^[[:space:]]*$" <<< "$donnees_brutes")
   espaces=$(echo "$donnees_brutes" | sed 's/./&\n/g' | grep -c " ")
   if [ $pleines -gt $espaces ] ; then
      echo -e "\n::: Les données sont organisées en liste" | tee -a $fichier_sortie
   else
      echo -e "\n::: Les données sont organisées en texte" | tee -a $fichier_sortie
   fi
}
# fin préliminaire-------------------fonction : postliminaire-------------------------------
postliminaire()
{
if [ $fichier_sortie != /dev/null ] ; then
   if ! [ -f $fichier_sortie ] || ! [ -s $fichier_sortie ] ; then
      echo -e "\n::: Le fichier '$fichier_sortie' n'existe pas, ou il est vide." | tee -a $fichier_sortie
   else
     taille=$(ls -l $fichier_sortie | awk -F" " '{print $5 " octets - " $6 " " $7 " " $8}')
     echo -e "\n::: Fichier $fichier_sortie : créé ($taille)" | tee -a $fichier_sortie
  fi
  if [ $option_csv == 1 ] ; then
     if ! [ -f $fichier_sortie.csv ] || ! [ -s $fichier_sortie.csv ] ; then
       echo -e "\n::: Le fichier '$fichier_sortie.csv' n'existe pas, ou il est vide." | tee -a $fichier_sortie
     else
       taille=$(ls -l $fichier_sortie.csv | awk -F" " '{print $5 " octets - " $6 " " $7 " " $8}')
       echo -e "\n::: Fichier $fichier_sortie.csv : créé ($taille)" | tee -a $fichier_sortie
     fi
  fi
  if [ $option_pdf == 1 ] ; then
     if ! [ -f $fichier_sortie.pdf ] || ! [ -s $fichier_sortie.pdf ] ; then
       echo -e "\n::: Le fichier '$fichier_sortie.pdf' n'existe pas, ou il est vide." | tee -a $fichier_sortie
     else
       taille=$(ls -l $fichier_sortie.pdf | awk -F" " '{print $5 " octets - " $6 " " $7 " " $8}')
       echo -e "\n::: Fichier $fichier_sortie.pdf : créé ($taille)" | tee -a $fichier_sortie
     fi
  fi
fi
}
# fin postliminaire -----------------fonction : petites fct suppression---------------------
  accent_capit="ÀÁÂĀÃÄÅĄÆÇČĎÐÈÉÊËĚÌÍÎĪÏÍŁÑŇÒÓÔŌÕÖØŒŘŠŞŤŢÙÚÛÜŮÝŸŶŽÞßẞ"
  accent_bdcas="àáâāãäåąæçčďđèéêëěìíîïīíłñňòóôōõöøœřšşťţùúûüůýÿŷžþßß"
   accent_tous="àáâāãäåąçčďđèéêëěìíîïīíłñňòóôōõöřšşťţùúûüůýÿŷžÀÁÂĀÃÄÅĄÇČĎÐÈÉÊËĚÌÍÎĪÏÍŁÑŇÒÓÔŌÕÖŘŠŞŤŢÙÚÛÜŮÝŸŶŽ"
no_accent_tous="aaaaaaaaccddeeeeeiiiiiilnnoooooorssttuuuuuyyyzAAAAAAAACCDDEEEEEIIIIIILNNOOOOOORSSTTUUUUUYYYZ"
# ---------
bas_de_casse()
{
   # sed y : replacement caractere pour caractere
   donnees=$(tr [A-Z] [a-z] <<< $donnees)
   donnees=$(sed -r -e "y/$accent_capit/$accent_bdcas/" <<< $donnees)
}
# ---------
supp_diacritique()
{
   donnees=$(sed -r -e "y/$accent_tous/$no_accent_tous/" <<< $donnees)
}
# ---------
supp_punct()
{
   donnees=$(sed -r -e 's/ʾ|\x27|’|“|”|%|‰|,|\.|\\|\/|\$|£|€|<|=|>|;|:|\(|\)|\[|\]|\{|\}|!|\?|\"|-|@|#|\*|_|\||§|&|~|\^|`|µ|\+|°|\xe2\x80\x93|−|«|»|½|¼|÷|×|¡|¿|…|·|²|³|®|±|\´|º|¥|©|¨|¾|¹|¸|ª|¦|¶|¤|¢/ /g' <<< $donnees)
   supp_ajout="supprimés "
}
supp_chiffre()
{
   donnees=$(sed 's/[0-9]/ /g' <<< $donnees)
}
# fin petite fct suppression---------fonction : syllabeur----------------------------------
syllabeur()
{
    trap 'setterm -cursor on;
       echo -e "\n" ;
       echo -e "::: Mots analysés : $nb_mots - Temps passé : $(($SECONDS/3600)) heure(s), $(($SECONDS%3600/60)) minute(s) et $(($SECONDS%60)) seconde(s)\n " ;
       exit' HUP INT
   echo $(setterm -cursor off)
   if [ $lister_liste == 1 ] ; then
      echo -e "::: Nombre de syllabes par mot" | tee -a $fichier_sortie
      echo -e "::: Rang;nombre;syllabes et symboles" | tee -a $fichier_sortie
   fi
   # les donnees sont réduites aux minuscules. L'algorithme est adapté de
   # celui de Pailler [1999] qui porte sur les phonèmes et non sur l'alphabet
   donnees=$(echo $donnees | tr '\n\r\f' ' ')
   donnees=$(echo $donnees | sed -e 's/\([A-Z][A-Za-z0-9]*\)/\L\1/g')

   for mot in $donnees ; do
       sortie=$(awk ' BEGIN {
       FS=" ";
       OFS=" ";
       V="[aàâäeéèêëiïoôöuùûüyÿæœ]"; # voyelles
       C="[bcçdfghjklmnpqrstvwxz-]"; # consonnes lato sensu
       }
       {
          n=1
          a=$n
          while (i=match(a, V C V)) {
             a=substr(a,1,i) "/" substr(a,i+1, length(a)); n++}
          while (i=match(a, V V V V)) {
             a=substr(a,1,i+1) "/" substr(a,i+2, length(a)); n++}
          while (i=match(a, V C V V)) {
             a=substr(a,1,i) "/" substr(a,i+1, length(a)); n++}
          while (i=match(a, C V C C V)) {
             a=substr(a,1,i+2) "/" substr(a,i+3, length(a)); n++}
          while (i=match(a, V C C V)) {
             a=substr(a,1,i+1) "/" substr(a,i+2, length(a)); n++}
          while (i= match(a, V C C C V)) {
             a=substr(a,1,i+1) "/" substr(a,i+2,length(a)); n++}
          while (i=match(a, V C C C C V)) {
             a=substr(a,1,i+1) "/" substr(a,i+2,length(a)); n++}
          while (i=match(a, V C C C C C V)) {
             a=substr(a,1,i+1) "/" substr(a,i+2,length(a)); n++}
          # compute the CVY skeleton
          sk= "";
          for (i=1;i<=length(a);i++) {
             ph=substr(a,i,1);
             if (ph~V) sk=sk"V";
             else if (ph~C) sk=sk"C";
             else sk=sk ph;
           }
       } { print "\n",n,a,sk } ;' <<< $mot) # fin de sortie=awk
       # formatage de la sortie
       sortie=$(echo $sortie | awk '{print " :::", $1, "=>", $2, "("$3")" }')
       nb_mots=$(($nb_mots + 1))
       if [ $lister_liste == 1 ] ; then
          echo $nb_mots" "$sortie | tee -a $fichier_sortie
       else
          echo -e -n "\033[s"
          echo -e -n "::: Calcul du nombre de syllabes en cours. Ctrl-c pour interrompre. Mots analysés :  $nb_mots"
          echo -e -n "\033[u"
       fi
       sortie2=$sortie2$sortie

   done # on est sorti de la gande boucle for mots in donnees
   # on peut alors comptabiliser les syllabes
   sortie2=$(sed -e 's/:::/\n:::/g' <<< $sortie2)
   NumCol=2
   nb_syllabes=$(awk -F ' ' -v champ="$NumCol" '{ total += $champ } END {print total}' <<<$sortie2)
   # nb_M3_syllabes = nombre de mots de plus de trois syllabes
   nb_M3_syllabes=$(awk -F ' ' -v champ="$NumCol" '{if($champ>3) {cpt+=1}} END {if (cpt) {print cpt} else {print 0}}' <<<$sortie2)
   if [ $lister_liste == 1 ] ; then
      echo | tee -a $fichier_sortie
      echo -e "::: Répartition des mots par nombre de syllabes" | tee -a $fichier_sortie
      echo -e "::: Rang;syllabes;nombre de mots" | tee -a $fichier_sortie
      for Valeur in `seq 1 10` ; do
         compt=$(awk -F ' ' -v champ="$NumCol" -v value="$Valeur" '{if($champ==value) {cpt+=1}} END {print cpt}' <<<$sortie2 )
         if [ $compt ]; then
            let rang++
            echo -e "$rang ::: $Valeur => $compt" | tee -a $fichier_sortie
         fi
      done
      echo -e "Nombre total de syllabes : $nb_syllabes" | tee -a $fichier_sortie
   fi
   unset sortie sortie2 Valeur NumCol
   echo $(setterm -cursor on)
   trap "echo ;exit" HUP INT # retour à l'état par défaut
}
# fin syllabeur----------------------fonction : nb per mots---------------------------------
# deux fonctions car difficile de passer des parametres avec init_tab_awk
nb_per_mots()
{
   # Paramètre pour initialiser le script awk.
   compteur=0
   for lettre in $liste_mots
   do
      init_tab_awk="$init_tab_awk tab_jeton[${compteur}] =  \"$lettre\"; tab_nombre[${compteur}] = 0; tab_total[${compteur}] =  0 ;"
      # A passer comme paramètres au script awk ci-dessous.
      compteur=$(expr $compteur + 1)
   done
   # echo $init_tab_awk | sed 's/tab_jeton/\ntab_jeton/g'; # pour debug
   awk \
   "BEGIN { $init_tab_awk } \
   { split(\$0, tab, \" \"); \
   for (caractere in tab) \
      { for (caractere2 in tab_jeton) \
         { if (tab_jeton[caractere2] == tab[caractere]) \
             { tab_nombre[caractere2]++ } \
             { tab_total[caractere2] = tab_total[caractere2 -1 ] + tab_nombre[caractere2] }  } } } \
   END { for (caractere in tab_nombre) \
      { print \"::: \" tab_nombre[caractere] \" => \" tab_jeton[caractere] } {print \"::: Total : \" tab_total[caractere]  } }" <<< $donnees
}
# fin nb_per_mots--------------------fonction : nb_per_char---------------------------------
nb_per_char()
{
   # Paramètre pour initialiser le script awk.
   compteur=0
   for lettre in $liste_car
   do
      init_tab_awk="$init_tab_awk tab_jeton[${compteur}] =  \"$lettre\"; tab_nombre[${compteur}] = 0; tab_total[${compteur}] =  0 ;"
      # A passer comme paramètres au script awk ci-dessous.
      compteur=$(expr $compteur + 1)
   done
   # echo $init_tab_awk | sed 's/tab_jeton/\ntab_jeton/g'; # pour debug
   awk \
   "BEGIN { $init_tab_awk } \
   { split(\$0, tab, \"\"); \
   for (caractere in tab) \
      { for (caractere2 in tab_jeton) \
         { if (tab_jeton[caractere2] == tab[caractere]) \
             { tab_nombre[caractere2]++ } \
             { tab_total[caractere2] = tab_total[caractere2 -1 ] + tab_nombre[caractere2] }  } } } \
   END { for (caractere in tab_nombre) \
      { print \"::: \" tab_nombre[caractere] \" => \" tab_jeton[caractere] } {print \"::: Total : \" tab_total[caractere]  } }" <<< $donnees 2>/dev/null
}
# fin nb_per_char--------------------fonction : onyva---------------------------------------
onyva()
{
   data_a_analyser=$1
   liste=$2
   compteur=0
   for lettre in $(echo $liste)    # Pour chacune...
      do
         tableau_awk="$tableau_awk tab_lettre[${compteur}] = \"$lettre\"; tab_nombre[${compteur}] = 0; "
         # A passer comme paramètres au script awk ci-dessous.
         compteur=$(expr $compteur + 1)
      done
   # echo $tableau_awk # Pour debug
   echo $data_a_analyser |
   awk \
   "BEGIN { $tableau_awk } \
      { split(\$0, tab, \"\"); \
      for (caractere in tab) \
         { for (caractere2 in tab_lettre) \
            { if (tab_lettre[caractere2] == tab[caractere]) { tab_nombre[caractere2]++ } } } } \
      END { for (caractere in tab_nombre)
          { total += tab_nombre[caractere] }
          { print total } } " 2>/dev/null
}
# fin onyva -------------------------fonction : opérations monétaires-----------------------
operations_monetaires()
{
   # remplacement des espaces des expressions monétaires par des insécables fines
   esp_avant=$(echo $donnees | sed 's/./&\n/g' | grep -c " ")
   donnees=$(sed  -r -e 's/( |^)([0-9]{1,3}) ([0-9]{3}[^)($|[^0-9])/\1\2\xe2\x80\xaf\3/g' \
                     -e 's/([0-9]{3}) ([0-9]{3}[^)($|[^0-9])/\1\xe2\x80\xaf\2/g' \
                     -e 's/([0-9]{3}) ([0-9]{3}[^)($|[^0-9])/\1\xe2\x80\xaf\2/g' <<< $donnees)

   esp_apres=$(echo $donnees | sed 's/./&\n/g' | grep -c " ")
   esp_monetaires=$(($esp_avant - $esp_apres))
   # comptage  point et virgule monétaires
   pt_virg_monetaires=$(echo $donnees | sed -r -e 's/([0-9][\.,][0-9])/\1\n/g' | wc -l)
   pt_virg_monetaires=$(($pt_virg_monetaires -1))
}
# fin des opérations monétaires------fonction : filtrer-------------------------------------
filtrer()
{
donnees_int=$1
      # suppression des points sauf dans les nombres et les mots
      donnees_int=$(sed -r -e 's/(^|[^[a-zA-Z0-9])\.+([^a-z]|$)/\1 \2/g' <<< $donnees_int)
      # suppression des virgules sauf dans les nombres (US style)
      donnees_int=$(sed -r -e 's/(^|[^0-9])\,+([^0-9]|$)/\1 \2/g' <<< $donnees_int)
      # suppression des points et virgules qui subsistent en fin de mot et de ligne
      donnees_int=$(sed -r -e 's/(\.|,)([\x20\x0a\x0d\x0a]|$)+/ /g' <<< $donnees_int)
      # suppression des degrés sauf dans les nombres
      donnees_int=$(sed -r -e 's/(^|[^0-9])°([^0-9]|$)/\1 \2/g' <<< $donnees_int)
      # Suppression des slashs =sauf dans les nombres et les mots=
      donnees_int=$(sed -r -e "s/(^| |$accent_tous)\/+|\/+([^a-zA-Z0-9]|$)/\1 \2/g" <<< $donnees_int)
      # Suppression de % =non suivi d'une espace
      donnees_int=$(sed -r -e 's/(‰|%)([^ ]+)/ \2/g' <<< $donnees_int)
      # Suppression des % dont le prédécesseur n'est pas un nombre avec ou sans espace
      donnees_int=$(sed -r -e 's/([^0-9 ])(%|‰)/\1/g' <<< $donnees_int)
      # Suppression du reste des % sans toucher aux formes conservées type 12,5% ou 12 %
      donnees_int=$(sed -r -e 's/([^0-9] )[%|‰]( )/\1\2/g' <<< $donnees_int)
      # Remplacement des espaces par des insécables fines  pour les % et les glyphes monétaires
      donnees_int=$(sed -r -e 's/([0-9])[ ](%|‰|\$|£|€|¥)/\1\xe2\x80\xaf\2/g' <<< $donnees_int)
      # Suppression des glypes isolés. En une seule passe, ça ne passe pas !
      donnees_int=$(echo $donnees_int | sed -r -e 's/([^0-9] )[£]( |$)/\1\2/g' | sed -r -e 's/([^0-9] )+[£]( |$)/\1\2/g')
      donnees_int=$(echo $donnees_int | sed -r -e 's/([^0-9] )[$]( |$)/\1\2/g' | sed -r -e 's/([^0-9] )+[$]( |$)/\1\2/g')
      donnees_int=$(echo $donnees_int | sed -r -e 's/([^0-9] )[€]( |$)/\1\2/g' | sed -r -e 's/([^0-9] )+[€]( |$)/\1\2/g')
      donnees_int=$(echo $donnees_int | sed -r -e 's/([^0-9] )[¥]( |$)/\1\2/g' | sed -r -e 's/([^0-9] )+[¥]( |$)/\1\2/g')
      # Reste des autres suppressions
      donnees_int=$(sed -r -e 's/’{2,}|ʾ| ’|’ |“|”|<|=|>|;|:|\(|\)|\[|\]|\{|\}|!|\?|\"| -|- |-{2,}|@|#|\*| _|_ |_{2,}|\||§|&|~|\^|`|µ|\+|\xe2\x80\x93|−|«|»|½|¼|÷|×|¡|¿|…|·|²|³|®|±|\´|º|©|¨|¾|¹|¸|ª|¦|¶|¤|¢/ /g' <<< $donnees_int)
      # suppression apostrophe x27 sauf dans les mots
      donnees_int=$(sed -r -e 's/([[:space:]][\x27]|[[:punct:]][\x27]|[\x27][[:space:]]|[\x27][[:punct:]])/ /g' <<< $donnees_int)
      donnees_int=$(sed -r -e 's/([^[:alnum:]][\x27]|[\x27]$)/ /g' <<< $donnees_int)
}
# fin filtrer------------------------fonction : analyse par mots commun---------------------
analyse_par_mots_commun()
{
   # dans la fonction set -f supprime l'expansion des * en directory
   set -f
   if [ $type_entree == directe ]; then
      octets=$(wc -c < "$1")
      total_lignes=$(sed -n -e '$=' $1)
      vides=$(grep -c -E "^[[:space:]]*$" "$1")
      pleines=$(grep -v -c -E "^[[:space:]]*$" "$1")
      espaces=$(sed 's/./&\n/g' "$1" | grep -c " ")
   else
      octets=$(wc -c <<< "$donnees_brutes")
      total_lignes=$(sed -n -e '$=' <<< $donnees_brutes)
      vides=$(grep -c -E "^[[:space:]]*$" <<< "$donnees_brutes")
      pleines=$(grep -v -c -E "^[[:space:]]*$" <<< "$donnees_brutes")
      espaces=$(echo "$donnees_brutes" | sed 's/./&\n/g' | grep -c " ")
   fi
   if [ $pleines -gt $espaces ] ; then
      type="liste"
      # acquisition des données avec remplacement des espaces par des tildes (ou insécables normales)
      # donnees=$(cat $1 | sed 's/\r//' | sed -e 's/ /\xc2\xa0/g')
      donnees=$(echo "$donnees_brutes" | sed 's/\r//' | tr ' ' '~')
      # passage de iconv (ne convertit pas les CR LF FF)
      donnees=$(iconv -f $char_set -t utf-8 <<< $donnees)
      if [ "$bas_de_casse" == "1" ];then
         bas_de_casse
      fi
      if [ "$diacritique" == "1" ];then
         supp_diacritique
      fi
      if [ "$supp_punct" == "1" ];then
         echo "::: L'option supression de la ponctuation ne s'applique pas aux listes"
      fi
      if [ "$supp_chiffre" == "1" ];then
         echo "::: L'option supression des chiffres ne s'applique pas aux listes"
      fi
      other=0
      autres=0
      nb_total_insecables=0
   else
      type="texte"
      # copie fichier avec substitution des \ par #, et CR LF et FF  ce qui ne change rien ensuite aux comptages
      donnees=$(echo $donnees_brutes | tr '\n\r\f' ' ' | tr '\\' '#')
      # passage iconv (ne convertit pas les CR LF FF)
      donnees=$(iconv -f $char_set -t utf-8 <<< $donnees)
      liste1='\x27 ’ ! \" #  “ ” % ‰ & ( ) \* + , - . / : ; < = > ? @ [ \\ ] ^ _ ` { | } ~ ¡ § « ° » ¿ ÷ × − – $ £ € ½ ¼ ʾ µ …  · ² ³ ® ± ´ º ¥ © ¨ ¾ ¹ ¸ ª ¦ ¶ ¤ ¢'
      nb_total_punct=$(onyva "$donnees" "$liste1")
      if [ -z $nb_total_punct ] ; then
         echo -e "\n::: Dépassement de capacité mémoire. Abandon\n" | tee -a $fichier_sortie
         echo -e "::: Temps passé : $(($SECONDS/3600)) heure(s), $(($SECONDS%3600/60)) minute(s) et $(($SECONDS%60)) seconde(s)\n " | tee -a $fichier_sortie
         exit
      fi
      nb_total_phrases=$(echo $donnees | sed -r -e  's/[.!?](\x20|$)/µµµµ\n/g' | grep -c µµµµ)
      if [ $nb_total_phrases == 0 ] ; then
         nb_total_phrases=1
      fi
      if [ $option_monetaire == 1 ]; then
         operations_monetaires
      fi
      if [ "$supp_chiffre" == "1" ];then
         supp_chiffre
      fi

      filtrer "$donnees"
      donnees=$donnees_int
      unset donnees_int

      liste3="- _ . , / ' ’ $ £ € % ‰"
      nb_punct_dans_mots=$(onyva "$donnees" "$liste3")
      liste4="\xc2\xa0 \xe2\x80\xaf"
      nb_total_insecables=$(onyva "$donnees" "$liste4")
      if [ "$bas_de_casse" == "1" ];then
         bas_de_casse
      fi
      if [ "$diacritique" == "1" ];then
         supp_diacritique
      fi
      if [ "$supp_punct" == "1" ];then
         supp_punct
      fi
      if [ "$option_syllabeur" == "1" ] && ! [ "$syllabeur_fait" == "1" ] ;then
         syllabeur
         syllabeur_fait=1
      fi
   fi
}
# fin analyse par mots commun--------fonction : analyse par mots détail---------------------
analyse_par_mots_detail()
{
   # passage de la variable de chaîne en tableau
   donnees=($donnees)
   if [ $lister_m_texte == 1 ] && [ $lister_liste == 1 ]; then
      echo | tee -a $fichier_sortie
      echo -e "::: Taille des mots" | tee -a $fichier_sortie
      echo "::: Rang;longueur en lettres;mot" | tee -a $fichier_sortie
   fi
   car_in_mots=0
   for i in ${!donnees[@]} ; do
      long=$((${#donnees[$i]}))
      car_in_mots=$(($car_in_mots + $long))
      if [ $lister_m_texte == 1 ] && [ $lister_liste == 1 ] ; then
         echo $(($i +1)) "::: $long => ${donnees[$i]}"
         if ! [ "$fichier_sortie" == "/dev/null" ]; then
            echo $(($i +1)) "::: $long => ${donnees[$i]}" >> $fichier_sortie
         fi
         sortie=$sortie" "$long
      fi
   done

   # on peut faire le calcul de la répartition des mots par nombre de lettres
   if [ $lister_m_texte == 1 ] && [ $lister_liste == 1 ] ; then
      echo -e "\n::: Répartition des mots par nombre de lettres" | tee -a $fichier_sortie
      echo -e "::: Rang;longueur en lettres; nombre de mots" | tee -a $fichier_sortie
      rang=0
      sortie=$(sed -e 's/ /\n/g' <<< $sortie)
      for Valeur in `seq 1 26` ; do
         compt=$(awk -F ' ' -v value="$Valeur" '{if($1 == value) {cpt+=1}} END {print cpt}' <<<"$sortie" )
         if [ $compt ] ; then
            let rang++
            echo -e "$rang ::: $Valeur => $compt" | tee -a $fichier_sortie
         fi
      done
   fi

   nb_mots=$(($i + 1))

   if [ $car_in_mots -gt 0 ]; then
      moy_car=$(echo "scale=5; $car_in_mots/$nb_mots" | bc -l)
   else
      moy_car=0
      nb_mots=0
   fi
   if [ $type == texte ]; then
      autres=$(($nb_total_punct - $nb_punct_dans_mots))
      moy_phrase=$(echo "scale=5; $nb_mots/$nb_total_phrases" | bc -l)
      complexite=$(echo "scale=5; ($moy_car - 4.2 + 7*l($moy_phrase) - 8)/1.3" | bc -l)
      coleman=$(echo "scale=5; (5.88*$moy_car - 0.296*(100/$moy_phrase) - 15.8)" | bc -l)
      ari=$(echo "scale=5; (4.71*$moy_car + 0.5*$moy_phrase - 21.43)" | bc -l)
      # après calcul on limite le nb de décimales, mais printf depend de la locale séparateur
      # et LANG=C ou LC_NUMERIC=C ne marche pas sur toutes les distributions
      moy_car_=$(printf "%.2f\n" "$moy_car" 2>/dev/null)
      if [ $? == 1 ] ; then
         moy_car=${moy_car/./,}
         moy_phrase=${moy_phrase/./,}
         complexite=${complexite/./,}
         coleman=${coleman/./,}
         ari=${ari/./,}
         moy_car_=$(printf "%.2f\n" "$moy_car")
      fi
      moy_car=${moy_car_/,/.}
      moy_phrase_=$(printf "%.2f\n" "$moy_phrase")
      moy_phrase=${moy_phrase_/,/.}
      complexite=$(printf "%.2f\n" "$complexite")
      complexite=${complexite/,/.}
      coleman=$(printf "%.2f\n" "$coleman")
      coleman=${coleman/,/.}
      ari=$(printf "%.2f\n" "$ari")
      ari=${ari/,/.}
      if [ $option_syllabeur == 1 ] ;then
         flesh_1=$(echo "scale=5; 206.835 - 1.015*($nb_mots/$nb_total_phrases) - 84.6*($nb_syllabes/$nb_mots)" | bc -l)
         flesh_2=$(echo "scale=5; 0.39*($nb_mots/$nb_total_phrases) + 11.8*($nb_syllabes/$nb_mots) - 15.59" | bc -l)
         gunning=$(echo "scale=5; 0.4*(($nb_M3_syllabes*100/$nb_mots) + $moy_phrase)" | bc -l)
         smog=$(echo "scale=5; 1.0430*(sqrt($nb_M3_syllabes*30/$nb_total_phrases)) + 3.1291" | bc -l)
         flesh_1_=$(printf "%.2f\n" "$flesh_1" 2>/dev/null)
         if [ $? == 1 ] ;then
            flesh_1=${flesh_1/./,}
            flesh_1_=$(printf "%.2f\n" "$flesh_1")
            flesh_2=${flesh_2/./,}
            gunning=${gunning/./,}
            smog=${smog/./,}
         fi
         flesh_1=${flesh_1_/,/.}
         flesh_2=$(printf "%.2f\n" "$flesh_2")
         flesh_2=${flesh_2/,/.}
         gunning=$(printf "%.2f\n" "$gunning")
         gunning=${gunning/,/.}
         smog=$(printf "%.2f\n" "$smog")
         smog=${smog/,/.}
         moy_indices=$(echo "scale=2; ($complexite+$coleman+$ari+$flesh_2+$gunning+$smog)/6" | bc -l)
      fi
   fi
   echo -e "\n::: Analyse par détail des mots :::" | tee -a $fichier_sortie
   echo -e "$donnees_source$ligne_commande | Type : $type | Charset : $char_set | Octets : $octets" | tee -a $fichier_sortie
   if [ $type == texte ]; then
      echo "::: Lignes : $total_lignes | Dont vides : $vides | Espaces sécables : $espaces | Autres car. impr. $supp_ajout: $autres"  | tee -a $fichier_sortie
      echo "::: Nombre de mots : $nb_mots | Nombre de caractères de toute nature : "$(($total_lignes + $car_in_mots + $espaces + $autres)) | tee -a $fichier_sortie
      echo "::: Nombre de caractères composant les mots : $car_in_mots | Dont insécables : $nb_total_insecables | Dont ponct. : $nb_punct_dans_mots" | tee -a $fichier_sortie
      if [ $option_monetaire == 1 ]; then
         echo "::: Espaces monetaires remplacés : $esp_monetaires | Points et virgules monetaires inclus en mots : $pt_virg_monetaires" | tee -a $fichier_sortie
      fi
      if [ $option_syllabeur == 1 ]; then
         echo "::: Longueur moyenne des mots : $moy_car caractères | Syllabes : $nb_syllabes" | tee -a $fichier_sortie
      else
         echo "::: Longueur moyenne des mots : $moy_car caractères" | tee -a $fichier_sortie
      fi
      echo "::: Nombre de phrases : $nb_total_phrases | Longueur moyenne des phrases : $moy_phrase mots" | tee -a $fichier_sortie
      echo "::: Indice de lisibilité spécifique : "$complexite | tee -a $fichier_sortie
      echo "::: Indice de Coleman-Liau : $coleman - Indice ARI : $ari "| tee -a $fichier_sortie
      if [ $option_syllabeur == 1 ]; then
         echo -e "::: Indice Flesh-Kincaid général : $flesh_1 - Flesh-Kincaid niveau d'éducation : $flesh_2" | tee -a $fichier_sortie
         echo -e "::: Indice Gunning-Fog : $gunning - Indice SMOG : $smog - Moyenne des indices éducation : $moy_indices" | tee -a $fichier_sortie
      fi
   else
      echo "::: Caractères composant les mots : $car_in_mots | Dont espaces sécables : $espaces" | tee -a $fichier_sortie
      echo "::: Mots : $nb_mots | Lignes : $total_lignes | Dont vides : $vides" | tee -a $fichier_sortie
      moy_car_=$(printf "%.2f\n" "${moy_car/./,}" 2>/dev/null)
      if [ $? == 1 ] ; then
         moy_car=$(printf "%.2f\n" "${moy_car/,/.}")
      else
         moy_car=$(printf "%.2f\n" "${moy_car/./,}")
      fi
      moy_car=${moy_car/,/.}
      echo "::: Longueur moyenne des mots : $moy_car caractères" | tee -a $fichier_sortie
   fi
   echo "::: ----------------------------------------------------------------------------" | tee -a $fichier_sortie
}
# fin analyse par mots détail--------fonction : affichage frequence------------------------
affichage_frequence()
{
   taux_h=$(echo "scale=5; $hapax*100/$nb_mots_1" | bc -l)
   taux_h_=$(printf "%.2f\n" "$taux_h" 2>/dev/null)
   if [ $? == 1 ] ; then
      taux_h=${taux_h/./,}
      taux_h_=$(printf "%.2f\n" $taux_h)
   fi
   taux_h=${taux_h_/,/.}

   taux_u=$(echo "scale=5; $nb_mots_1*100/$nb_mots_avant" | bc -l)
   taux_u_=$(printf "%.2f\n" "$taux_u" 2>/dev/null)
   if [ $? == 1 ] ; then
      taux_u=${taux_u/./,}
      taux_u_=$(printf "%.2f\n" $taux_u)
   fi
   taux_u=${taux_u_/,/.}

   echo -e "\n::: Analyse par fréquence des mots :::" | tee -a $fichier_sortie
   echo -e "$donnees_source$ligne_commande" | tee -a $fichier_sortie
   echo -e "::: Nombre de mots "$donnees_origine ": $nb_mots_avant" | tee -a $fichier_sortie
   echo -e "::: Nombre de mots du vocabulaire $du_fichier_fourni: $nb_mots_1 - Taux vocabulaire/total : $taux_u %" | tee -a $fichier_sortie
   if [ $nb_mots_xx != 0 ] ; then
      echo -e "::: Nombre de mots $deplus : $nb_mots_xx" | tee -a $fichier_sortie
   fi
   echo -e "::: Nombre d'hapax $deplus: $hapax - Taux hapax/vocabulaire : $taux_h %" | tee -a $fichier_sortie
   echo -e "::: Indice de Gini : $indice_gini - Indice de Gini hors hapax : $indice_gini_h"| tee -a $fichier_sortie
   echo -e "::: Indice de Shannon : $indice_shannon - Indice de Simpson : $indice_simpson"| tee -a $fichier_sortie
   echo "::: ---------------------------------------------------------------------------" | tee -a $fichier_sortie
}
# fin affichage fréquence------------fonction : calcul variable temporaire-----------------
calcul_variable_temp()
{
# cette fonction établit variable_temp pour tous les traitements. Elle n'incopore plus
# le traitement de lister_f_alpha et lister_i_alpha comme dans les versions antérieures à v6.00
nb_mots_1=$(echo $liste_mots_1 | sed 's/./&\n/g' | grep -c " ")
nb_mots_1=$(($nb_mots_1 + 1))
passe=$(($nb_mots_1 / 1000 + 1 ))
debut=1
pas=999
i=0
while [ "$i" -lt "$passe" ] ; do
   i=$(($i + 1))
   echo -e "::: $(date '+%H:%M:%S') - Passe $i sur $passe"
   liste_mots=$(echo $liste_mots_1 | cut -f $debut-$(($debut+$pas)) --delimiter=" ")
   resultats=$(nb_per_mots)
   # on affiche au fur et à mesure de chaque passe : supprimé v6.00
   # echo $resultats | sed 's/:::/\n:::/g'
   variable_boucle=$(echo $resultats | sed 's/:::/\n:::/g' | sed 's/ $//g')
   # On peut nourir le fichier de sortie, supprimé v6.00 . Jamais de tee dans une boucle
   # if ! [ "$fichier_sortie" == "/dev/null" ] && [[ $lister_f_alpha == 1 || $lister_i_alpha == 1 ]] ; then
      # echo -e "::: Passe $i sur $passe\c" >> $fichier_sortie
      # echo $resultats | sed 's/:::/\n:::/g' >> $fichier_sortie
   #fi
   debut=$(($debut + $pas +1 ))
   variable_temp=("$variable_temp $variable_boucle")
done
}
# fin calcul variable temporaire-----fonction : calcul des indices -----------------------
calcul_indice()

{
   if [ "$2" == "supp_l1" ]; then
      variable_indice=$(sed '1d' <<< $1)
   else
      variable_indice=$1
   fi

   variable_indice=$(echo -e "$variable_indice" | sed '/Total/d')
   # l'entropie ne supporte pas les occurrences nulles
   variable_shannon=$(grep -v "::: 0 =>" <<< $variable_indice)
   if [ -n "$variable_shannon" ] ; then
      indice_shannon=$(awk -v N=$nb_mots_avant -v S=$nb_mots_1 ' { B=$2 } ; { if (N!=1 && S!=1) {H += ((B/N)*log(B/N))/log(S)} else H = -0} ; \
          END { if (N!=1) {printf "%.4f\n", -H} else printf "%s\n", "non calculable"}' <<< $variable_shannon )
   else
      indice_shannon="non calculable"
   fi
   indice_simpson=$(awk -v N=$nb_mots_avant ' { A += $2*($2-1) } ; { if (N!=1) B = N*(N-1)} ; {if (N!=1) D = 1-(A/B)} ;  \
          END { if (N!=1) {printf "%.4f\n", D} else printf "%s\n", "non calculable"}' <<< $variable_indice)

   variable_gini=$(echo -e "$variable_indice" | sort -n -k 2 | nl )
   indice_gini=$(awk '{A += $1*$3} ; {B += $3} ; END  {if (B != 0) {printf "%.4f\n", 1-((2*A)/(NR*B)-(NR+1)/(NR))} else printf "%s\n", "non calculable"}' <<< $variable_gini)

   variable_gini_h=$(awk '$2 != "1" {print}'  <<< $variable_indice)
   variable_gini_h=$(echo -e "$variable_gini_h" | sort -n -k 2 | nl )
   indice_gini_h=$(awk '{A += $1*$3} ; {B += $3} ; END  {if (B != 0) {printf "%.4f\n", 1-((2*A)/(NR*B)-(NR+1)/(NR))} else printf "%s\n", "non calculable"}' <<< $variable_gini_h)
}
# fin calcul indices-----------------fonction : analyse de la frequence des mots-----------
analyse_par_mots_frequence()
{
   # établissement de la liste des mots index à appliquer aux données à analyser
   nb_mots_avant=$(echo $donnees | sed 's/./&\n/g' | grep -c " ")
   nb_mots_avant=$(($nb_mots_avant +1))
   echo -e "\n::: Analyse par fréquence des mots :::" | tee -a $fichier_sortie

   # on sépare les cas fichier fourni ou non
   # on traite les deux cas de demande de frequence du texte ou xxx
   if [[ $lister_f_alpha == "1" || $lister_f_freq == "1" || $lister_x_alpha == "1" || $lister_x_freq == "1" ]] ; then

      if [ $type_entree == directe ];then
         echo -e "::: les mots indexés sont ceux du fichier analysé" | tee -a $fichier_sortie
      else
         echo -e "::: les mots indexés sont ceux du flux pipé ou redirigé" | tee -a $fichier_sortie
      fi
      # liste_mots_1 est la liste des mots singuliers provenant du texte
      liste_mots=$(awk "BEGIN { $tableau_awk } { split(\$0, tab, \" \"); for (mots in tab) { print tab[mots] } }" <<< $donnees )
      liste_mots_1=$(echo $liste_mots | tr ' ' '\n' | sort -u)
      # la fonction calcul_variable_temp incorporait l'édition alpha. Mais avant on neutralise
      # lister_i_alpha pour eviter edition indue dans la fonction lors d'un appel avant fichier_fourni
      if [ $lister_i_alpha == 1 ] ; then
         lister_i_alpha=0
         lister_i_alpha_tmp=1
      fi
      calcul_variable_temp
      calcul_indice "$variable_temp" "supp_l1"
      hapax=$(echo "$variable_temp" | grep "::: 1 " | wc -l)
      if [ $lister_i_alpha_tmp == 1 ] ; then
         lister_i_alpha=1
      fi

      if [ $lister_f_alpha == "1" ] && [ $lister_liste == 1 ] ; then
         # sortie triée dans l'ordre alphabétiuqe
         echo -e "\n::: Fréquence des mots (par ordre alphabétique)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         variable_temp=$(sort -t " " -k 4b,4 -k 2rn,2 <<< $variable_temp)
         variable_temp=$(sed -r -e '/Total.*$/d' <<< sed -r -e '/^ $/d' <<< $variable_temp)
         echo "$variable_temp" | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie

      fi # lister f alpha

      if [ $lister_f_freq == "1" ] && [ $lister_liste == 1 ] ; then
         # sortie triée dans l'ordre des fréquences
         echo -e "\n::: Fréquence des mots (par ordre décroissant des fréquences)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         variable_temp=$(sort -t " " -k 2rn,2 -k 4b,4 <<< $variable_temp)
         variable_temp=$(sed -r -e '/Total.*$/d' <<< sed -r -e '/^ $/d' <<< $variable_temp)
         echo "$variable_temp" | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie

      fi # lister f fréquence

      if [ $lister_f_alpha == "1" ] || [ $lister_f_freq == "1" ] ; then
         deplus=""
         affichage_frequence
      fi

      if [ $lister_x_alpha == "1" ] || [ $lister_x_freq == "1" ] ; then
         # on traite ensuite le cas de sortie -x=
         echo -e "\n::: Mots du texte analysé de plus de $yyy lettre(s) de plus grande fréquence ($xxx demandés) :::" | tee -a $fichier_sortie
         variable_temp=$(sed -r -e '/Total.*$/d' <<< sed -r -e '/^ $/d' <<< $variable_temp)
         variable_temp=$(awk -v yyy_awk=$yyy '{if (length($4) > yyy_awk) print $0 }' <<< $variable_temp)
         variable_temp_alpha=$(echo "$variable_temp" | sort -t" " -k 2rn,2 -k 4b,4 | sed -n '1, '$xxx' p'| sort -t" " -k 4b,4 -k 2rn,2 )
         variable_temp_freq=$(echo "$variable_temp" | sort -t" " -k 2rn,2 -k 4b,4 | sed -n '1, '$xxx' p')
         nb_mots_xx=$(echo "$variable_temp_alpha" | wc -l)
         hapax=$(echo "$variable_temp_alpha" | grep "::: 1 " | wc -l)
         if [ ${#variable_temp_alpha} == 0 ] && [ ${#variable_tem_freq} == 0 ] ; then
            echo -e "::: Aucun mot ne correspond à votre requête."
         else
            calcul_indice "$variable_temp_freq"
         fi
      fi

      if [ $lister_x_alpha == 1 ] && [ $lister_liste == 1 ] ; then
         echo -e "\n::: Fréquence des mots (par ordre alphabétique)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         echo "$variable_temp_alpha" | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      fi # option lister x alpha

      if [ $lister_x_freq == 1 ] && [ $lister_liste == 1 ] ; then
         echo -e "\n::: Fréquence des mots (par ordre décroissant des fréquences)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         echo "$variable_temp_freq" | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      fi # option lister x freq

      if [ $lister_x_alpha == "1" ] || [ $lister_x_freq == "1" ] ; then
         deplus="de plus de $yyy lettres "
         affichage_frequence
      fi
      unset variable_temp variable_temp_alpha variable_temp_freq variable_boucle

   fi # fin deux cas texte ou xxx

   # on traite alors l'option fichier fourni
   if [[ $lister_i_alpha == "1" || $lister_i_freq == "1" ]] ; then
      echo -e "\n::: les mots indexés sont ceux du fichier '$fichier_fourni'" | tee -a $fichier_sortie
      # Liste_mots_1 fournie. On commence par la nettoyer
      # traitement du charset du fichier fourni
      liste_mots_1=$(cat $fichier_fourni)
      char_set_fichier_fourni=$(file -i "$fichier_fourni" | sed -e "s/.*charset=//")
      if [ "$char_set_fichier_fourni" == "unknown-8bit" ]; then
        char_set_fichier_fourni=437
      fi
      liste_mots_1=$(iconv -f $char_set_fichier_fourni -t utf-8 <<< $liste_mots_1)

      # ici il est plus simple de ne pas passer par une fct pour les suppressions
      if [ "$supp_chiffre_i" == "1" ] ; then
          liste_mots_1=$(tr -d [:digit:] <<< $liste_mots_1)
      fi
      filtrer "$liste_mots_1"
      liste_mots_1=$donnees_int
      unset donnees_int
      if [ "$bas_de_casse_i" == "1" ] ; then
         liste_mots_1=$(tr [A-Z] [a-z] <<< $liste_mots_1 )
         liste_mots_1=$(sed -r -e "y/$accent_capit/$accent_bdcas/" <<< $liste_mots_1)
      fi
      if [ "$diacritique_i" == "1" ] ; then
         liste_mots_1=$(sed -r -e "y/$accent_tous/$no_accent_tous/" <<< $liste_mots_1)
      fi

      # on trie ne fût-ce que pour éliminer les doublons saisis
      liste_mots_1=$(echo $liste_mots_1 | tr '\n\r\f' ' ' | sed -r -e 's/ /\n/g' | sort -u)

      # la fonction calcul_variable_temp n'incorpore plus l'édition alpha depuis la v6.00
      calcul_variable_temp
      calcul_indice "$variable_temp" "supp_l1"
      hapax=$(echo "$variable_temp" | grep "::: 1 " | wc -l)
      du_fichier_fourni="du fichier $fichier_fourni "

      if [ $lister_i_freq == "1" ] && [ $lister_liste == 1 ] ; then
         # sortie triée dans l'ordre des fréquences
         echo -e "\n::: Fréquence des mots (par ordre décroissant des fréquences)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         variable_temp=$(sort -t " " -k 2rn,2 -k 4b,4 <<< $variable_temp)
         variable_temp=$(sed -r -e '/Total.*$/d' <<< sed -r -e '/^ $/d' <<< $variable_temp)
         echo "$variable_temp" | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      fi # lister fréquence

      if [ $lister_i_alpha == "1" ] && [ $lister_liste == 1 ] ; then
         # sortie triée dans l'ordre alphabétique
         echo -e "\n::: Fréquence des mots (par ordre alphabétique)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         variable_temp=$(sort -t " " -k 4b,4 -k 2rn,2 <<< $variable_temp)
         variable_temp=$(sed -r -e '/Total.*$/d' <<< sed -r -e '/^ $/d' <<< $variable_temp)
         echo "$variable_temp" | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      fi # lister alpha
      deplus=""
      affichage_frequence
   fi # fin lister_i
}

# fin analyse par mots frequence-----fonction : analyse par caractères---------------------
analyse_par_caracteres()
{
   # dans la fonction set -f supprime l'expansion des * en directory
   set -f
   # Supression de CR LL FF non breaking space normal et fine
   donnees=$(echo $donnees_brutes | sed 's/[\x0a\x0d\x0c\xc2\xa0\xe2\x80\xaf]/ /g')
   # passage iconv (ne convertit pas les CR LF FF)
   donnees=$(iconv -f $char_set -t utf-8 <<< $donnees)
      if [ "$bas_de_casse" == "1" ];then
         bas_de_casse
      fi
      if [ "$diacritique" == "1" ];then
         supp_diacritique
      fi
      if [ "$supp_chiffre" == "1" ];then
         supp_chiffre
      fi
      if [ "$supp_punct" == "1" ];then
         supp_punct
      fi
   # établissement de la liste des caractères des données à analyser
   liste_car=$(awk "BEGIN { $tableau_awk } { split(\$0, tab, \"\"); for (caractere in tab) { print tab[caractere] } }" <<< $donnees )
   liste_car=$(echo $liste_car | tr ' ' '\n' | sort -u)
   # indispensable antislashage de \ (pas évident) ` et "
   liste_car=$(echo $liste_car | sed -r -e 's/[\x5c]/\\\\/g' | sed -r -e 's/`/\\`/g' | sed -r -e 's/"/\\"/g')
   liste_tmp=$(echo $liste_car | tr -d ' ')
   l_liste_tmp=${#liste_tmp}
   resultats=$(nb_per_char)
   # nb_char_dans_car est la somme des nombres des caractères listés
   nb_chars_dans_car=$(echo $(expr match "$resultats" '.*\( [0-9]*\)'))
   if [ -z $nb_chars_dans_car ] ; then
      echo -e "\n::: Dépassement de capacité mémoire. Abandon\n" | tee -a $fichier_sortie
      echo -e "::: Temps passé : $(($SECONDS/3600)) heure(s), $(($SECONDS%3600/60)) minute(s) et $(($SECONDS%60)) seconde(s)\n " | tee -a $fichier_sortie
      exit
   fi
   echo -e "\n::: Analyse par caractères :::" | tee -a $fichier_sortie
   if [ $lister_c_alpha == 1 ] && [ $lister_liste == 1 ] ; then
      echo -e "::: Caractères comptabilisés : "$liste_car | tee -a $fichier_sortie
      echo -e "::: Fréquence des caractères (par ordre alphabétique)" | tee -a $fichier_sortie
      echo -e "::: Rang;fréquence;caractère" | tee -a $fichier_sortie
      resultats=$(sort -t " " -k 4b,4 -k 2rn,2 <<< $resultats)
      resultats=$(sed -r -e '/Total.*$/d' <<< sed -r -e '/^ $/d' <<< $resultats)
      if [ $option_csv == 0 ] ;then
         awk -v awk_local=$nb_chars_dans_car 'CONVFMT = "%.2f" {print $1,$2,$3,$4, "= " $2*100/awk_local, "%"}' <<< $resultats | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      else
         awk -v awk_local=$nb_chars_dans_car 'CONVFMT = "%.2f" {print $1,$2,$3,$4, "= " $2*100/awk_local, "%"}' <<< $resultats | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g'
         echo "$resultats" | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g' >> $fichier_sortie
      fi
   fi
   if [ $lister_c_freq == 1 ] && [ $lister_liste == 1 ] ; then
      if [ $lister_c_alpha == 1 ] ; then echo ; fi | tee -a $fichier_sortie
      echo -e "::: Caractères comptabilisés : "$liste_car | tee -a $fichier_sortie
      echo -e "::: Fréquence des caractères (par ordre décroissant des fréquences)" | tee -a $fichier_sortie
      echo -e "::: Rang;fréquence;caractère" | tee -a $fichier_sortie
      resultats=$(sort -t " " -k 2rn,2 -k 4b,4 <<< $resultats)
      resultats=$(sed -r -e '/Total.*$/d' <<< sed -r -e '/^ $/d' <<< $resultats)
      if [ $option_csv == 0 ] ;then
         awk -v awk_local=$nb_chars_dans_car 'CONVFMT = "%.2f" {print $1,$2,$3,$4, "= " $2*100/awk_local, "%"}' <<< $resultats | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      else
         awk -v awk_local=$nb_chars_dans_car 'CONVFMT = "%.2f" {print $1,$2,$3,$4, "= " $2*100/awk_local, "%"}' <<< $resultats | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g'
         echo "$resultats" | nl | sed -r -e 's/^\s*([0-9]*)\x09/\1 /g' >> $fichier_sortie
      fi
   fi
   echo -e "\n::: Analyse par caractères :::" | tee -a $fichier_sortie
   echo -e "$donnees_source$ligne_commande " | tee -a $fichier_sortie
   echo -e "::: Nombre de caractères (espaces non compris) : "$l_liste_tmp | tee -a $fichier_sortie
   echo -e "::: Nombre d'occurrences de ces caractères : "$nb_chars_dans_car | tee -a $fichier_sortie
   echo "::: ---------------------------------------------------------------------------" | tee -a $fichier_sortie
}
# fin analyse par caractères---------fonction : verification-------------------------------
verification()
{
   echo -e "\n::: Vérification :::\n" | tee -a $fichier_sortie
   echo -e "$donnees_source$ligne_commande " | tee -a $fichier_sortie
   if [ $type == texte ]; then
      if [ "$supp_punct" == "1" ] ; then
         balance=$(($car_in_mots - $nb_total_insecables - $nb_chars_dans_car))
      else
         balance=$(($car_in_mots + $autres - $nb_total_insecables - $nb_chars_dans_car))
      fi
   else
      balance=$(($car_in_mots - $espaces - $nb_chars_dans_car))
   fi
   if [ $balance == 0 ] ;then
      echo "::: Les résultats de l'analyse par mots et par caractères correspondent" | tee -a $fichier_sortie
      echo "::: Les chiffres donnés peuvent être tenus pour vrais" | tee -a $fichier_sortie
   fi
   if [ $balance -lt 0 ] ;then
      echo "::: Les résultats de l'analyse par mots et par caractères ne correspondent pas ($balance)" | tee -a $fichier_sortie
      echo -e "::: Des signes graphiques du fichier de données '"$1"' ne sont pas connus du module d'analyse par mots ($balance)" | tee -a $fichier_sortie
      echo "::: Les chiffres de l'analyse par caractères sont justes" | tee -a $fichier_sortie
   fi
   if [ $balance -gt 0 ] ;then
      echo "::: Les résultats de l'analyse par mots et par caractères ne correspondent pas ($balance)" | tee -a $fichier_sortie
      echo "::: Raison inconnue, merci de signaler ce cas" | tee -a $fichier_sortie
   fi
   echo "::: ----------------------------------------------------------------------------"
}
# fin verification-------------------fonction : mots2csv-----------------------------------
mots2csv()
{
   # un peu répétitif, mais clair et l'enchaînement des sed par pipe ne marche qu'en partie seulement
   donnees=$(sed -r -e 's/(^::: )(.*)/\2/g' <<< cat $fichier_sortie)
   donnees=$(sed -r -e 's/ ::: /;/g' <<< $donnees)
   donnees=$(sed -r -e 's/(.*)( => )(.*)/\1;"\3\"/g' <<< $donnees)
   donnees=$(sed -r -e '/^[0-9]|^Rang|^Fr.quence|^Taille|^R.partition|^Nombre/!d' <<< $donnees)
   donnees=$(sed -r -e '/^Fr.quence|^Taille|^R.partition|^Nombre/{x;p;x}' <<< $donnees)
   donnees=$(sed -r -e 's/^Fr.quence .*|^Taille .*|^R.partition .*|^Nombre .*/&;;/g' <<< $donnees)
   echo -e "$donnees\n" > $fichier_sortie.csv
}
# fin mots2csv ----------------------fonction : mots2pdf-----------------------------------
mots2pdf()
{
   type enscript &>/dev/null
   if [ $? == 0 ]; then
      taille=$(ls -l $fichier_sortie | awk -F" " '{print $5 " octets - " $6 " " $7 " " $8}')
      echo -e "\n::: Fichier $fichier_sortie : créé ($taille)" >> $fichier_sortie
      if [ $option_csv == 1 ] ; then
         taille=$(ls -l $fichier_sortie.csv | awk -F" " '{print $5 " octets - " $6 " " $7 " " $8}')
         echo -e "\n::: Fichier $fichier_sortie.csv : créé ($taille)" >> $fichier_sortie
      fi
      echo -e "\n::: Fichier $fichier_sortie.pdf : en cours de création ("$(date '+%d %b %X')")" >> $fichier_sortie
      echo -e "\n::: Temps passé : $(($SECONDS/3600)) heure(s), $(($SECONDS%3600/60)) minute(s) et $(($SECONDS%60)) seconde(s)\n " >> $fichier_sortie
      # la "mauvaise" apostrophe fait planter iconv, donc la transforme. Les autres mauvais char sont supprimé par -c
      cat $fichier_sortie | sed -r -e "s/\’/\'/g" | enscript --output=- --filter="iconv -c -f utf-8 -t ISO-8859-1" \
          -B --margin=20:5:5:5: -f Helvetica@9/10 -j 2>/dev/null | ps2pdfwr - > $fichier_sortie.pdf
      # il faut maintenant supprimer les n dernieres lignes du fichier de sortie
      if [ $option_csv == 0 ] ; then
         sed -n -e :a -i -e '1,7!{P;N;D;};N;ba' $fichier_sortie
      else
         sed -n -e :a -i -e '1,9!{P;N;D;};N;ba' $fichier_sortie
      fi
   else
      echo -e "\n::: Il faut installer 'enscript'. Le fichier $fichier_sortie.pdf ne peut pas être généré"
   fi
}
# fin mots2pdf ----------------------main--------------------------------------------------

preliminaire

if [ "$analyse_mots_detail" == "1" ] ; then
   analyse_par_mots_commun $*
   analyse_par_mots_detail $*
fi
if [ "$analyse_chars" == "1" ] ; then
   analyse_par_caracteres $*
fi
if [ "$analyse_frequence" == "1" ] ; then
   analyse_par_mots_commun $*
   analyse_par_mots_frequence
fi
if [ "$verification" == "1" ] ; then
   verification $*
fi
if [ "$option_csv" == "1" ] ; then
   mots2csv $*
fi
if [ "$option_pdf" == "1" ] ; then
   mots2pdf $*
fi

postliminaire

echo -e "\n::: Temps d'exécution : $(($SECONDS/3600)) heure(s), $(($SECONDS%3600/60)) minute(s) et $(($SECONDS%60)) seconde(s)\n " | tee -a $fichier_sortie


