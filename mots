#!/bin/bash

origin=mots
version="6.60 b-20221227"

# pour debug
# set -x
# date
# file="tmp$(date +%m%d-%H%M%S)"
# cp "$0" "$file"
# rm -f encours_va*.log
# source mots_variables
# affiche_var ${LINENO} 0
# fin pour debug

LC_ALL=C
if ! [ $LANG == fr_FR.UTF-8 ] ; then
    LANG=fr_FR.UTF-8
fi

if [ ! -t 0 ]; then
   type_entree=pipee    # entrée des données par pipe "|" ou redirection "<"
else
   type_entree=directe  # entrée des données par fichier désigné dans la ligne de commnade
fi

usage()
{
      echo -e "\n::: Usage : $(basename $0) [--help | --version] [OPTIONS]... FICHIER | redirection"
}

#-------------------------------------test entrée directe------------------------------------
if [ $type_entree == directe ];then
   if [ $# -lt 1 ];then
      usage
      echo -e "::: Le fichier à analyser n'est pas indiqué\n"
      exit
   fi
   if [[ $@ == *--version* ]] ; then
      echo -e "\n::: $(basename $0) version : $version\n"
      exit
   fi

#-------------------------------------dont le help-------------------------------------------
if [[ $@ == *--help* ]] ; then
echo -e "\n\e[1;97mPRESENTATION GENERALE\e[0m"
cat << EOF

   Usage     $(basename $0) [--help | --version] [OPTIONS]... FICHIER | redirection

   Objet     le logiciel $(basename $0) version $version décompte les mots, les syllabes, les
             phrases et les caractères d'un texte ou d'une liste ; il calcule la longueur des
             mots et des phrases et fait leurs moyennes. Il compte la fréquence des caractères
             et des mots, avec de nombreuses possibilités : il permet par exemple la recherche
             de la fréquence des mots d'un vocabulaire donné ou d'une longueur donnée. Il
             calcule tous les indices classiques de lisibilité auxquels il ajoute un indice
             spécifique. Il calcule trois indicateurs de richesse de vocabulaire. Il comprend
             de nombreuses options et sous-options. Il restitue les données de manière
             détaillée ou synthétique à l'écran ou dans un fichier de type texte ou PDF. Il
             peut établir un fichier de sortie au format CSV pour retraitements externes.
EOF
echo -e "\n\e[1;97mOPTIONS ET SOUS-OPTIONS\e[0m"
cat << EOF

   --help    la présente aide
   --version version

   ANALYSE DES MOTS
             sans arguments, '$(basename $0)' affiche la synthèse de l'analyse du texte soumis, avec
             les longueurs moyennes des mots et des phrases (pour les textes), le nombre de
             phrases, de mots, de lignes, de caractères et calcule les trois indices de
             lisibilité de Coleman-Liau, ARI et un indice spécifique, sans lister les mots du
             texte.

      -l     fait de même et liste les mots avec leur longueur individuelle et leur rang dans
             l'ordre du texte et donne la répartition des mots selon leur taille en nombre de
             lettres et signes.

      -s     liste les mots décomposés en syllabes, les décompte, indique la répartition des
             mots par nombre de syllabes et ajoute les quatre indices de lisibilité de Flesh-
             Kincaid général, Flesh-Kincaid éducation, Gunning-Fog et SMOG. L'usage de
             l'option -s0 est suggéré.

   FREQUENCE DES CARACTERES
             les deux options ci-après établissent la fréquence des caractères du texte
             analysé avec le pourcentage que représente chacun (hors espaces).

      -ca    liste les caractères du texte avec leur fréquence dans l'ordre alphabétique.

      -cf    liste les caractères du texte avec leur rang et leur fréquence dans l'ordre de
             leur fréquence et dans l'ordre alphabétique en second rang.

   FREQUENCE DES MOTS
             toutes les options ci-après calculent la fréquence des mots et les quatre indices
             de dispersion du vocabulaire de Gini, Gini hors happax, Shannon et Simpson.
             L'usage de l'option -sc est suggéré.

      -fa    liste les mots du texte avec leur fréquence dans l'ordre alphabétique.

      -ff    liste les mots du texte avec leur rang et leur fréquence dans l'ordre de leur
             fréquence et dans l'ordre alphabétique en second rang.

      -xa    liste les mots du texte, déterminé par les sous-options -x=XXX et -y=YY, avec
             leur fréquence dans l'ordre alphabétique.

      -xf    liste les mots du texte, déterminé par les sous-options -x=XXX et -y=YY, avec
             leur rang et leur fréquence dans l'ordre de leur fréquence.

      -x=XXX liste les XXX premières fréquences des mots du texte analysé. Maximum 999999. Par
             défaut XXX=20. Toujours associé à une valeur de YY. Nécessite -xa ou -xf.

      -y=YY  liste les fréquences des mots du texte analysé de plus de YY caractères. Par
             défaut YY=3. Minimum 1. Maximum 64. Toujours associé à une valeur de XXX.
             Nécessite -xa ou -xf.

      -z=ZZ  liste les fréquences des mots du texte analysé d'exactement ZZ caractères.
             Minimum 1. Maximum 64. Toujours associé à une valeur de XXX. Nécessite -xa ou -xf.

      -i=FICHIER
             FICHIER est un fichier de vocabulaire qui contient les mots dont on recherche la
             fréquence dans le texte analysé. Le séparateur des mots dans FICHIER est l'espace.
             Ces mots peuvent comprendre apostrophe, tiret, tiret inférieur, barre oblique,
             espace insécable ainsi que point et virgule pour les nombres. Tout autre signe
             est ignoré (notamment les glyphes monétaires). FICHIER peut comporter tiret,
             tiret inférieur et point mais pas d'espace. Option -ia ou -if obligatoire.

      -ia    liste les mots du texte présents dans le fichier de vocabulaire défini par
             -i=FICHIER avec leur fréquence dans l'ordre alphabétique.

      -if    liste les mots du texte présents dans le fichier de vocabulaire avec leur rang et
             leur fréquence dans l'ordre de leur fréquence.

      -isc   remplace les capitales par des bas-de-casse dans le fichier de vocabulaire.

      -isd   remplace les caractères avec signes diacritiques par les mêmes sans signes
             diacritiques dans le fichier de vocabulaire.

      -is0   supprime les chiffres (0 à 9) dans le fichier de vocabulaire.

      -ic=CHARSET
             charset du fichier de vocabulaire forcé à CHARSET et non à la valeur décelée par
             le programme.

   REGROUPEMENT D'OPTIONS

      -z    regroupe les options -s -fa -sl de sorte que toutes les données et tous les
            indices sont affichés de manière synthétique par une seule commande.

   SOUS-OPTIONS GENERALES
             les sous-options générales s'appliquent aux analyses des mots et à celles des
             fréquences pour les textes seulement (seules les options -sc et -sd peuvent
             s'appliquer aux listes).

      -m     remplace les espaces des expressions monétaires numériques exprimées par groupes
             de trois chiffres par des espaces insécables, de sorte que ces expressions
             deviennent des mots.

      -sc    remplace les capitales par des bas de casse dans les données analysées.

      -sd    remplace les caractères avec signes diacritiques par les mêmes sans signes
             diacritiques.

      -sp    supprime toute la "ponctuation", selon la liste qui figure à l'article du même
             nom ci-dessous, y compris au sein des mots du texte analysé. Ainsi 'nid-de-poule'
             (un mot) se découpe alors en trois mots 'nid' 'de' 'poule'.

      -s0    supprime les chiffres (de 0 à 9) des données analysées. Entraine la suppression
             des signes situés entre les chiffres et des glyphes pouvant les suivre.

      -sl    annule l'impression détaillée des listes et n'affiche que la synthèse des
             analyses.

      -c=CHARSET
             charset du fichier à analyser forcé à CHARSET et non à la valeur décelée par le
             programme.

      -o=FICHIER
             envoie le résultat écran également dans le fichier FICHIER. Le crée s'il n'existe
             pas. FICHIER peut comporter tiret, tiret inférieur et point mais pas d'espace.

      -pdf   réalise une copie du fichier FICHIER au format PDF ; ce fichier prend le nom de
             FICHIER avec l'extension .pdf

      -csv   réalise une copie des données numériques du fichier FICHIER au format CSV pour
             traitements mathématiques ou graphiques externes (loi de Zipf par exemple).
             Séparateur de champs  ";" chaînes encadrées par des doubles quotes. Ce fichier
             prend le nom de FICHIER avec l'extension .csv

      -?     les options non listées ci-dessus sont ignorées.

   VERIFICATION

      -v     valide les chiffres donnés par vérification de la concordance entre les résultats
             de l'analyse des mots et de celle des caractères.
EOF
echo -e "\e[1;97mDEFINITIONS\e[0m"
cat << EOF

   DEFINITIONS GENERALES

      FICHIER
             en argument de la ligne de commande, désigne le nom du fichier à analyser. Ce nom
             peut représenter tout fichier informatique (a priori composé de texte), pour tout
             charset. Le logiciel vérifiera le type et écartera les fichiers non exploitables :
             binaires, fichiers au format traitement de texte en particulier. Ce fichier
             sera débarassé des éventuels détritus qu'il peut comporter. Il nest pas possible
             d'indiquer plusieurs noms de fichiers. Le fichier indiqué peut compendre un ou
             plusieurs espaces. Les paramétres de remplacement ( * et ? ) peuvent être utilisés
             si leur usage conduit à la désignation d'un seul fichier et si le globbing est
             actif (peut l'être par la commande 'set +f').

      liste  est considérée comme liste toute suite de caractères et de signes divers figurant
             sur une ligne distincte. Chaque ligne est considérée comme formant un seul mot,
             l'auteur étant seul responsable de ce qu'il considère comme tel. Aucun traitement
             automatique n'est effectué sur les listes. Seules les options -sc -sd peuvent
             leur être appliquées.

      texte  texte quelconque pouvant comprendre tous les signes figurant ou pouvant être
             composés sur les différents claviers latins nationaux.

      type   liste ou texte. Type déterminé par le logiciel selon le critère suivant : une
             liste comprend moins d'espaces sécables que de lignes.

      mot    EN LISTE. Toute suite de caractères figurant sur une même ligne, par exemple "eau
             de vie" sans tirets est considéré comme un seul mot. Tout autre signe figurant
             sur la ligne est compté dans la longueur du mot, y compris les éventuelles
             espaces finales.

             EN TEXTE. Toute suite continue de caractères alphabétiques ou numériques séparée
             par une espace sécable. Ainsi "eau de vie" sans tirets sera considéré comme trois
             mots, sauf si les espaces sont des insécables. Les mots comportant apostrophe,
             tiret, tiret inférieur, barre oblique, espace insécable, point forment un seul
             mot comme "arc-en-ciel", "aujourd’hui", "O'Connor", "10/18" ou "www.societe.com".
             Ces règles sont ici étendues aux nombres, considérés comme des mots, qui peuvent
             comprendre, en outre, virgule et signe degré, comme dans "6,35" ou "37°2". De
             plus, les nombres suivis, avec ou sans espace sécable, des signes "%, ‰" ou d'un
             des glyphes monétaires "€, £, ¥ ou $" sont considérés comme un seul mot.

      vocabulaire
             ensemble des mots présents une ou plusieurs fois dans le texte. Cet ensemble
             correspond à la 'richesse spécifique' des études de diversité. Aucun regroupement
             n'est effectué : ainsi, tous les mots issus d'une même racine (conjugaison par
             exemple) constituent autant de mots uniques différents constitutifs du
             vocabulaire.

      phrase
             ensemble de signes se terminant par un point, un point d'interrogation ou un
             point d'exclamation suivi d'une espace ou situé en fin de ligne.

      syllabe
             mot court ou partie de mot comprenant au moins une voyelle.

      nombre de caractères de toute nature
             le nombre de caractères de toute nature est la somme du nombre de caractères
             composant les mots, du nombre d'espaces sécables, du nombre d'autres caractères
             imprimables et du nombre de lignes.

      autres caractères imprimables
             tout signe imprimable figurant à l'article 'ponctuation', autre que chiffres et
             lettres, apostrophe, tiret, tiret inférieur, barre oblique, espace insécable et
             point interne aux mots, point et virgule internes aux nombres, signes "%, ‰" et
             glyphes monétaires quand ils suivent un nombre. Il en résulte qu'un signe
             orphelin (supposons "%") sera considéré comme  un "autre" alors qu'il composera
             un nom s'il suit un chiffre. La liste des autres  caractères ne comprend que les
             plus utilisés. Il en existe des milliers d'autres qui apparaîtront alors comme
             autant de mots.

      ponctuation
             la notion de ponctuation est considérée lato sensu. Aux onze signes académiques
             s'en ajoute de nombreux autres. La liste actuelle comprend les 72 suivants ! " #
             % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ \` { | } ~ ¡ § « ° » ¿ × ÷ – ’ “ ”
             ‰ − $ £ € ½ ¼ ʾ µ … · ² ³ ® ± ´ º ¥ © ¨ ¾ ¹ ¸ ª ¦ ¶ ¤ ¢ •

      charset
             jeu de caractères, de l'anglais "character set", façon de représenter de manière
             informatique une liste donnée de caractères. Ici, le charset du fichier original
             est détecté par le logiciel (sauf si -c=CHARSET est défini) et converti ensuite
             en utf-8 pour traitements. Le charset ISO_8859-1 est attribué par défaut aux
             charsets non reconnus. Il est parfois nécessaire de le forcer à une autre valeur
             en cas d'échec de conversion par 'iconv' ou de résultats aberrants.

      ligne vide
             vide au sens visuel. Peut en réalité comprendre ou non des espaces.

      hapax
             mot ne présentant qu'une seule occurence dans le texte analysé.

   INDICES DE LISIBILITE
             Les indices de lisibilité sont les indices classiques auxquels s'ajoute un indice
             spécifique. Ils sont toujours calculés avec leur formule canonique, mais à partir
             de nombres de mots, syllabes et phrases qui respectent nos propres conventions.
             Les éventuelles réserves sont exprimées ci-après. Les indices 'syllabiques'
             exigent l'option -s qui demande un temps de calcul plus élevé que les indices
             non-syllabiques. Ces derniers reposent sur la seule longueur des mots et des
             phrases, tandis que les premiers font appel en outre au nombre de syllabes. Les
             linguistes anglo-saxons font la correspondance entre ces indices et le niveau
             d'éducation (grade level).

      indice spécifique
             indice non syllabique. Le résultat va de 4 pour un niveau CP à plus de 19 pour
             'Le Discours de la Méthode'. Sa formule  est la suivante : longueur moyenne des
             mots moins 4,2 plus sept fois le logarithme népérien de la longueur moyenne des
             phrases moins 8, le tout divisé par 1,2.

      indice de Coleman-Liau
             indice non syllabique dû à Meri Coleman et T.L. Liau.

      indice ARI (Automated Readability Index)
             indice non syllabique. Provient de l'armée américaine dans les années 60. Destiné
             à s'assurer de la lisibilité des textes dactylographiés

      indice de Flesh-Kincaid général
             indice syllabique dû à Rudolf Flesh et Peter Kincaid. La libilité est d'autant
             plus grande que l'indice est élevé. L'indice 0 dénote un texte compliqué, 60 à
             80 un texte lisible pour des 12-15 ans. Mais cet indice peut prendre des valeurs
             extrêmes ou devenir négatif.

      indice éducation de Flesh-Kincaid
             indice syllabique, dû aux mêmes. Le niveau de cet indice est censé indiquer le
             niveau d'étude nécessaire pour lire correctement un texte. Peut en réalité
             prendre des valeurs qui dépassent nettement les niveaux d'éducation.

      indice de Gunning-Fog
             indice syllabique, dû à Robert Gunning. Le texte doit être débarassé des noms
             propres, du jargon, des mots composés, ce qui n'est pas le cas ici. Va de 8-9
             pour des textes de juniors ou adolescents à 17-18 pour des articles universi-
             taires. L'indice est calculé ici sur la totalité du texte et non sur un extrait.

      indice SMOG
             indice syllabique dû à G. Harry McLaughlin. Utilisé ici dans sa formule canonique
             mais repose sur la totalité du texte et non sur des extraits.

   INDICES DE DIVERSITE
             Les indices de diversité mesurent la richesse du vocabulaire employé. Ils
             proviennent tous d'autres champs scientifiques que celui de la linguistique
             (science économique, théorie de l'information et statistique).

      indice de Gini
             fonction mathématique, due à Corrado Gini, pour mesurer l'inégalité des revenus,
             adapté ici pour prendre en compte le poids des mots en fonction de leur
             fréquence. Afin de le rendre plus intuitif, il est inversé (1-G), 0 correspondant
             à une forte prépondérance des mots de grande fréquence, 1 à une égalité totale du
             poids de tous les mots. Il varie donc dans le même sens que les indices de
             diversité de Shannon et Simpson, mais ne mesure pas la même chose. Une variante
             est ici adjointe en un indice hors happax.

      indice de Shannon
             fonction de mesure de l'entropie, due à Claude Shannon, à la base de la théorie
             de l'information. Pour rendre cet indice plus cohérent avec les autres, il est
             ici ramené de 0 à 1 (par division du résultat par le logarithme du vocabulaire).
             Dès lors, 0 correspond à une diversité nulle des mots, 1 à une diversité totale.

      indice de Simpson
             fonction statistique, due à Edward Simpson, relative aux tirages au hasard. Les
             'espèces' sont ici les mots du vocabulaire. Afin de rendre cet indice plus
             intuitif et cohérent avec les deux autres, c'est en fait l'indice de diversité de
             Simpson  qui est ici représenté, 0 correspondant à une diversité nulle des mots,
             1 à une diversité totale. Par rapport à l'indice de Shannon, il majore
             l'importance des mots de faible occurrence et notamment des happax.

EOF
echo -e "\e[1;97mAVERTISSEMENTS ET MISES EN GARDE\e[0m"
cat << EOF

      réserves générales
             le présent script est destiné à l'examen de fichiers textes en vue d'en
             quantifier les composants principaux que sont les mots, leur décomposition en
             syllabes, et les caractères. Il comporte des choix, qui peuvent être discutés. Il
             n'a nulle prétention à l'exhaustivité : son usage se limite aux alphabets des
             langues latines et aux textes plutôt littéraires. Il est moins opérant pour les
             textes comportant des signes propres à une discipline particulière. La plus
             grande liberté est laissée à l'usager, qui peut notamment cumuler tous les choix
             d'options. Ces options peuvent être données dans n'importe quel ordre, mais
             l'ordre d'exécution des commandes n'est pas déterminé par l'ordre des arguments.
             Si l'option --version est présente, elle l'emporte sur toutes les autres et sera la
             seule à être exécutée. Il est va de même pour l'option --help.

      option -s
             la mise en oeuvre de cette option entraîne des temps de traitement qui peuvent
             être assez longs pour les textes volumineux. Elle est nécessaire au calcul des
             indices syllabiques.

      option -m
             l'activation de l'option -m regroupe tous les blocs de trois chiffres des
             expressions monétaires pour en faire un seul mot par remplacement des espaces
             simples par des insécables. Il en résulte une diminution du nombre d'espaces et
             de mots et une augmentation de la longueur de ces derniers. Le nombre de points
             et virgules inclus dans les mots est alors indiqué. Des effets indésirables
             peuvent se produire : des suites de chiffres qui ne sont pas des expressions
             monétaires peuvent être compactés (les expressions régulières ont des limites !).
             L'activation de l'option -l permet de connaître le résultat des traitements.

      options -sc et -sd
             tous les caractères latins sont reconnus (notamment ceux propres aux alphabets
             albanais, allemand, corse, espagnol, islandais, italien, norvégien, polonais,
             portugais, roumain, serbe, suédois et tchèque).

      option -i=FICHIER
             les composants du fichier FICHIER sont reconnus par le logiciel selon les règles
             qui prévalent à l'article mot ci-dessus. Les éventuels détritus sont éliminés.
             Attention, l'usage d'apostrophes différentes (' et ’) distinguent des mots
             différents.

      fréquences des caractères
             calculées hors espaces.

      interprétation des résultats
             l'interprétation des résultats pouvant surprendre qui n'a pas lu avec soin la
             présente aide, les espaces dans les listes sont remplacées par des tildes lors de
             l'affichage par -l.

             Le rapport du nombre de caractères, espaces, autres caractères au nombre d'octets
             n'est pas évident, un caractère pouvant correspondre de un à six octets selon le
             charcet. Seul l'us-acii assure l'égalité du nombre d'octets et de caractères. wc
             peut faire apparaître un nombre de mots un peu supérieur, ce qui est normal
             compte tenu de la définition très extensive de ce qu'est un mot pour wc.

             Les éventuelles séquences d'échappement non permises dans le texte source sont
             éliminées sans avertissement (FF entre autres).

             Le rapprochement de la comptabilité en mots et en caractères peut être vérifié
             par l'option -v. Cette vérification fait apparaître l'écart éventuel entre les
             deux comptabilités.

             Dans la répartition des mots par nombre de lettres, les mots de plus de 124
             caractères ne sont pas affichés.

             L'ordre alphabétique diffère en fonction de la définition de la langue par la
             'locale' qui ne peut être modifiée sur certains systèmes. Il en résulte des
             résultats qui peuvent varier de l'un à l'autre. La meilleure correspondance entre
             systèmes passe par l'activation des options -sc et -sd lors des recherches de
             fréquences de mots.

             La translitération en PDF de quelques caractères particuliers n'est pas parfaite.
             Ainsi, "œ" peut s'exprimer "½".

             L'algorithme de syllabation a été retenu en raison de sa simplicité, de sa
             modularité et de sa rapidité. A cette fin, les capitales et caractères avec
             diacritiques sont réduits. Il ne cherche pas la perfection : par exemple les
             schwas ne sont pas éliminés, la coupure apparaît parfois décalée et le nombre de
             syllabes est parfois augmenté ou diminué d'une unité. Mais les erreurs se
             compensent et le nombre de syllabes apparaîtra acceptable aux yeux du
             statisticien. La syllabation retenue est propre à la langue et aux caractères
             français.

             Tous les résultats sont affichés au dix-millième mais sont calculés de manière
             plus précise.

             La correspondance entre le niveau d'éducation et les indices de lisibilité (tous
             d'origine anglo-saxonne) n'a qu'une valeur limitée. Elle est dépourvue de toute
             signification pour certains indices dans les cas limites.

             Les valeurs calculées par le présent script et par d'autres automates peuvent
             être plus ou moins différentes en raison des différences de définition des
             concepts et des méthodes utilisées.

      bugs connus
             une mauvaise translittération peut parfois se produite pour les 'locales' non
             fr_FR, avec affichage du message "Invavid multibyte data detected. There may be
             a mismatch between your data and your locale". Disparait en général lors d'une
             relance de la commande.

      limites (volume, temps d'exécution)
             ce script permet de traiter des textes de grande taille. Sa vitesse et ses
             capacités d'exécution dépendent des ressources de l'ordinateur utilisé. Compter
             une à deux minutes par million de mots pour les analyses de mots et de caractères
             avec un CPU à 3.60 GHz. Le volume des fichiers traitables dépend de la taille de
             la mémoire. Compter un peu plus de 1,7 Go de mémoire par million de mots. Testé
             pour des fichiers de 57 millions de mots. L'option -s est un peu longue ; le
             calcul du nombre de syllabes et des indices syllabiques demandent entre une et
             deux heures pour un roman de 150 000 mots. Les calculs de fréquences de mots et
             de caractères ne prennent que quelques minutes pour des textes de cette taille,
             mais ce temps augmente rapidement avec le volume des données à analyser.

      exécutabilité
             ce script a été réalisé sous GNU bash, version 5.1.0(1)-release-(x86_64-redhat-
             linux-gnu), GNU sed version 4.8, GNU awk version 5.1.0. Il peut demander
             l'installation de certains modules (notamment 'file' 'iconv' 'bc' 'tput' ainsi
             que 'enscript' ou 'ps2pdfwr' pour l'édition des pdf), modules en principe
             disponibles dans toutes les distributions de Linux.

      bugs   merci de signaler bugs et suggestions à : paul at vidonne point fr

      licence
             Copyright (c) $(date +%Y) Paul Vidonne. Ce script peut être librement exécuté,
             diffusé et modifié dans les conditions de la 'Creative Commons Attribution-
             NonCommercial-ShareAlike 3.0 Unported License' (CC-BY-NC-SA) publiée par Creative
             Commons. Il est mis à disposition "tel quel", SANS AUCUNE GARANTIE de quelque
             nature que ce soit et auprès de qui que ce soit. Plus d'informations (en anglais)
             sur la licence à <https://creativecommons.org/licenses/by-nc-sa/3.0/>, texte
             intégral à  <https://creativecommons.org/licenses/by-nc-sa/3.0/legalcode>.

$(basename $0)/$origin                              $version                                  ----
EOF
echo
exit
fi # fin --help
fi # fin entree_directe

#fin tests entree directe------------entree des donnees-------------------------------------
if [ ! -t 0 ]; then
   # ici entrée pipée
   donnees_brutes=$(cat | tr -d '\0'; echo)
   donnees_brutes=${donnees_brutes%x}
   donnees_brutes=$(sed 's/.*\x0a$//g' <<< "$donnees_brutes")
   donnees_source="::: Données pipées : $(basename $0) "
   donnees_origine="de l'entrée pipée"
   ligne_cmd_ori=$*
   ligne_commande=$*
   nb_arg_ligne_cmd=$#
else
   # les donnees brutes ne peuvent etre saisie ici dans le désordre de la ligne de commande. voir plus bas
   donnees_source="::: Commande : $(basename $0) "
   ligne_cmd_ori=$*
   ligne_commande=$*
   nb_arg_ligne_cmd=$#
   if [[ $ligne_commande == *-i=* ]] ; then
      fichier_fourni=$(sed -E 's/.*-i=([a-zA-Z0-9\"-\"\._]*).*/\1/g' <<< $ligne_commande)
      option_fichier_fourni=1
      if [ -d $fichier_fourni ] ; then
          usage
          echo -e "::: '$fichier_fourni' est un répertoire. Il faut indiquer un fichier. Abandon\n"
          exit
      fi
      if ! [ -f $fichier_fourni ] || ! [ -s $fichier_fourni ] ; then
          usage
          echo -e "::: Le fichier '$fichier_fourni' n'existe pas, ou il est vide. Abandon\n"
          exit
      fi
      if [ $(file -i $fichier_fourni | sed -e "s/.*charset=//") == "binary" ] ; then
          usage
          echo -e ":::le fichier $fichier_fourni est un fichier binaire. Abandon\n"
          exit
      fi
      ligne_commande=$(sed -E "s/-i=$fichier_fourni//g" <<< $ligne_commande)
   fi
   if [[ $ligne_commande == *-o=* ]] ; then
      fichier_sortie=$(sed -E 's/.*-o=([a-zA-Z0-9\"-\"\._]*).*/\1/g' <<< $ligne_commande)
      ligne_commande=$(sed -E "s/-o=$fichier_sortie//g" <<< $ligne_commande)
      if [ -d $fichier_sortie ] ; then
          usage
         echo -e "::: '$fichier_sortie' est un répertoire. Il faut indiquer un fichier. Abandon\n"
         exit
      fi
      if [ -s $fichier_sortie ] ; then
         usage
         echo -e "::: Le fichier '$fichier_sortie' existe, mais il n'est pas vide. Abandon\n"
         exit
      fi
      if ! [ -f $fichier_sortie ] ; then
          echo -e "\n::: Le fichier '$fichier_sortie' n'existe pas, il est créée"
      elif ! [ -s $fichier_sortie ] ; then
          echo -e "\n::: Le fichier '$fichier_sortie' existe, il est vide et sera utilisé"
      fi
   fi
   objet=$(sed -E 's/(^|( )+)-[a-zA-Z0-9=\"-\"\._]+//g' <<< $* | xargs)
   if ! [ -z $objet ] ; then
      ligne_commande=$(sed -E "s/$objet//g" <<< $ligne_commande)
  fi
fi
#------------------------------------analyse de la ligne de commande-----------------------
# set -f incertain, donc if -24 destiné a contrer la présence d'une * comme seul argument
if [ $nb_arg_ligne_cmd -lt 24 ]; then
   analyse_chars=0
   analyse_frequence=0
   analyse_mots_detail=0
   bas_de_casse_i=0
   char_set=""
   egalite=0
   lister_c_alpha=0
   lister_c_freq=0
   lister_f_alpha=0
   lister_f_freq=0
   lister_i_alpha=0
   lister_i_alpha_tmp=0
   lister_i_freq=0
   lister_liste=1
   lister_m_texte=0
   lister_x_alpha=0
   lister_x_freq=0
   nb_mots_xx=0
   option_csv=0
   option_monetaire=0
   option_pdf=0
   option_syllabeur=0
   plus=" plus de"
   supp_chiffre_i=0
   verification=0
   xxx=20
   xxx_yyy=0
   yyy=3

   for i in $ligne_commande ; do
      arg=$i
      if [ $i == "-l" ]; then
         analyse_mots_detail=1
         lister_m_texte=1
      elif [ $i == "-s" ]; then
         analyse_mots_detail=1
         option_syllabeur=1
      elif [ $i == "-ca" ]; then
         analyse_chars=1
         lister_c_alpha=1
      elif [ $i == "-cf" ]; then
         analyse_chars=1
         lister_c_freq=1
      elif [ $i == "-fa" ]; then
         analyse_frequence=1
         lister_f_alpha=1
      elif [ $i == "-ff" ]; then
         analyse_frequence=1
         lister_f_freq=1
      elif [ $i == "-xa" ]; then
         analyse_frequence=1
         lister_x_alpha=1
      elif [ $i == "-xf" ]; then
         analyse_frequence=1
         lister_x_freq=1
      elif [ $i == "-ia" ]; then
         analyse_frequence=1
         lister_i_alpha=1
      elif [ $i == "-if" ]; then
         analyse_frequence=1
         lister_i_freq=1
      elif [ $i == "-m" ]; then
         option_monetaire=1
      elif [ $i == "-sc" ]; then
         bas_de_casse=1
      elif [ $i == "-sd" ]; then
         supp_diacritique=1
      elif [ $i == "-sp" ]; then
         supp_punct=1
      elif [ $i == "-s0" ]; then
         supp_chiffre=1
      elif [ $i == "-isc" ]; then
         bas_de_casse_i=1
      elif [ $i == "-isd" ]; then
         supp_diacritique_i=1
      elif [ $i == "-is0" ]; then
         supp_chiffre_i=1
      elif [ $i == "-sl" ]; then
         lister_liste=0
      elif [ $i == "-z" ]; then
         analyse_mots_detail=1
         option_syllabeur=1
         analyse_frequence=1
         lister_f_alpha=1
         lister_liste=0
      elif [ $i == "-v" ]; then
         analyse_mots_detail=1
         analyse_chars=1
         verification=1
      elif [ ${arg:0:4} == "-csv" ] ; then
         option_csv=1
      elif [ ${arg:0:4} == "-pdf" ] ; then
         option_pdf=1
      elif [ ${arg:0:3} == "-x=" ]; then
         xxx=${arg:3:6}
         if ! [[ $xxx == +([0-9]) ]] ; then
             usage
             echo -e "::: L'expression $xxx n'est pas un nombre. Abandon\n"
             exit
         fi
         xxx_yyy=1
     elif [ ${arg:0:3} == "-y=" ] || [ ${arg:0:3} == "-z=" ]; then
         if [ ${arg:5:1} ] ; then
            usage
            echo -e "::: L'expression -y= ou -z= ne doit contenir que deux chiffres. Abandon\n"
            exit
         fi
         yyy=${arg:3:2}
         if ! [[ $yyy == +([0-9]) ]] ; then
             usage
             echo -e "::: L'expression $yyy n'est pas un nombre. Abandon\n"
             exit
         elif [ $yyy -gt 64 ]; then
             echo -e "\n::: L'expression -y=$yyy ou -z=$yyy est ramenée à -y=64 ou -z=64. On continue"
             yyy=64
         elif [ $yyy ==  0 ]; then
             usage
             echo -e "::: L'expression -y=$yyy ou -z=$yyy n'est pas possible. Abandon\n"
             exit
         fi
         xxx_yyy=1
         if [ ${arg:0:3} == "-z=" ]; then
             egalite=1
             plus=""
         else
             egalite=0
         fi
      elif [ ${arg:0:3} == "-c=" ]; then
         char_set=${arg:3:20}
         iconv -l | grep -i -e "\b$char_set\b" >/dev/null
         if [ $? == 1 ] ; then
           usage
           echo -e "::: Le charset \"$char_set\" n'est pas reconnu. Abandon\n"
           exit
         fi
      elif [ ${arg:0:4} == "-ic=" ]; then
         char_set_i=${arg:4:21}
         iconv -l | grep -i -e "\b$char_set_i\b" >/dev/null
         if [ $? == 1 ] ; then
           usage
           echo -e "::: Le charset \"$char_set_i\" n'est pas reconnu. Abandon\n"
           exit
         fi
       else
         usage
         echo -e "::: La ligne de commande '$0 $ligne_cmd_ori' comprend des options non reconnues. Abandon\n"
         exit
      fi # de tous les if elif
   done # tous les i in ligne de commande
      # vérification de la cohérence des arguments
      if [[ $lister_i_alpha == "1" || $lister_i_freq == "1" ]] && [ -z $fichier_fourni ]; then
          usage
          echo -e "::: Pas de fichier défini par -i= . Abandon\n"
          exit
      fi
      if [[ $option_fichier_fourni == "1"  &&  $lister_i_alpha == "0" && $lister_i_freq == "0" ]] ; then
         usage
         echo -e "::: Avec un fichier fourni il faut préciser -ia ou -if. Abandon\n"
         exit
      fi
      if [ $xxx_yyy == 1 ] && [ $lister_x_alpha == 0 ] && [ $lister_x_freq == 0 ] ; then
         usage
         echo -e "::: Il faut accompagner -x=XXX, -y=YY ou -z=ZZ de -xa et/ou -xf. Abandon\n"
         exit
      fi
      if [[ $option_monetaire == "1"  &&  $supp_chiffre == "1" ]] ; then
         usage
         echo -e "::: Les deux options -m et -s0 sont contradictoires. Abandon\n"
         exit
      fi
      if [ $option_csv == 1 ] ; then
         if [ "$fichier_sortie" == "" ] ; then
            usage
            echo -e "::: Il faut un fichier de sortie (option -o=) pour obtenir un csv. Abandon\n"
            exit
         fi
         if [ -s $fichier_sortie.csv ] ; then
            usage
            echo -e "::: Le fichier '$fichier_sortie.csv' existe mais il n'est pas vide. Abandon\n"
            exit
         fi
         if [ $lister_liste == 0 ] ; then
            usage
            echo -e "::: Le fichier '$fichier_sortie.csv' serait vide compte tenu de l'option -sl. Abandon\n"
            exit
         fi
      fi
      if [ $option_pdf == 1 ] ; then
         if [ "$fichier_sortie" == "" ] ; then
            usage
            echo -e "::: Il faut un fichier de sortie (option -o=) pour obtenir un pdf. Abandon\n"
            exit
         fi
         if [ -s $fichier_sortie.pdf ] ; then
            usage
            echo -e "::: Le fichier '$fichier_sortie.pdf' existe mais il n'est pas vide. Abandon\n"
            exit
         fi
      fi
      # etablissement de l'analyse par defaut
      if [ "$analyse_mots_detail" != "1" ] && [ "$analyse_chars" != "1" ] && [ "$analyse_frequence" != "1" ];then
        analyse_mots_detail=1
        analyse_frequence=0
      fi
      if [ ! $fichier_sortie ] ; then
         fichier_sortie=/dev/null
      fi
      jour=$(date)
      echo -e "\n::: Le $jour" | tee -a $fichier_sortie
      echo -e "::: Programme : $0 version $version" | tee -a $fichier_sortie
      if ! [ $type_entree == directe ];then
         echo -e "::: Analyse flux pipé : $(basename $0) $ligne_cmd_ori " | tee -a $fichier_sortie
      fi
else
   usage
   echo -e "::: Trop d'arguments après $0 ('*'?). Abandon\n"
   exit
fi # fin nb arg ligne cmd inf à 24
# fin analyse ligne cmd--------------si direct test fichier à analyser----------------------
if [ $type_entree == directe ]; then # on teste le fichier a analyser
  if [ "$objet" == "" ] ; then
     usage
     echo -e "::: Le fichier à analyser n'est pas indiqué. Abandon\n"
     exit
   fi
   if ! [ -f "$objet" ] ; then
      usage
      echo -e "::: Le fichier '$objet' n'existe pas. Abandon\n"
      exit
   fi
   if ! [ -s "$objet" ] ; then
      usage
      echo -e "::: Le fichier '$objet' est vide. Abandon\n"
      exit
   fi
   echo -e "::: Analyse fichier : $objet" | tee -a $fichier_sortie
   echo -e "::: Daté : "$(stat -c %y "$objet" | cut -c 1-19) | tee -a $fichier_sortie
   echo -e "::: Empreinte SHA-1 :" $(sha1sum "$objet" | cut -c 1-40) | tee -a $fichier_sortie
   if [ "$char_set" == "" ] ; then
      char_set=$(file -i "$objet" | sed -e "s/.*charset=//")
   fi
   if [ "$char_set" == "unknown-8bit" ]; then
       echo -e "\n::: Le charset de '$objet' est inconnu. Forcé à ISO_8859-1, il peut être"
       echo -e "::: nécessaire de le redéfinir en cas d'échec de iconv ou de résultats aberrants"
       char_set=ISO_8859-1
   fi
   if [ "$char_set" == "binary" ]; then
      echo -e "\n::: le fichier '$objet' est un fichier binaire. Pas d'exploitation\n"
      exit
   fi
fi # fin entree directe

# avec entrée directe on peut enfin affecter donnees brutes, après vérifs ci-dessus
if [ -t 0 ]; then
    # ici set -f marche
    set -f
    IFS= read -rd '' donnees_brutes < "$objet"
    donnees_brutes=${donnees_brutes::-1}
fi

# fin test fichier analyse direct----test flux données si entree pipée----------------------
if [ $type_entree == pipee ]; then
   if [ ${#donnees_brutes} -eq 0 ];then
      usage
      echo -e "::: Le flux d'entrée est vide. Abandon\n"
      exit
   fi
   if [ "$char_set" == "" ] ; then
       char_set=$(echo $donnees_brutes | file -i - | sed -e "s/.*charset=//")
   fi
   if [ "$char_set" == "binary" ]; then
      echo -e "\n::: le flux de données est binaire. Pas d'exploitation\n"
      exit
   fi
fi # avec dans les deux cas
if [ "$char_set" == "unknown-8bit" ]; then
    echo -e "\n::: Le charset de l'entrée pipée est inconnu. Forcé à ISO_8859-1, il peut être"
    echo -e "::: nécessaire de le redéfinir en cas d'échec de iconv ou de résultats aberrants"
    char_set=ISO_8859-1
fi
# fin test flux données--------------rappels ------------------------------------------------
# \xc2\xa0 = insécable
# \xe2\x80\x93 = demi quadratin
# \xe2\x80\xaf = insécable fine
# \xe2\x80\x99 = apostrophe ’
# \xef\xbf\xbd = caractère de remplacement
# (\x08 \b BS) - (\x09 \t HT) - (\x0a \n LF) - (\x0b \v VT)
# (\x0c \f FF) - (\x0d \r CR) - (\c supprime le \n)
# fin rappels -----------------------fonction : préliminaire---------------------------------
preliminaire()
{
   pleines=$(grep -v -c -E "^[[:space:]]*$" <<< "$donnees_brutes")
   espaces=$(echo "$donnees_brutes" | sed 's/./&\n/g' | grep -c " ")
   if [ $pleines -gt $espaces ] ; then
      echo -e "\n::: Les données sont organisées en liste" | tee -a $fichier_sortie
   else
      echo -e "\n::: Les données sont organisées en texte" | tee -a $fichier_sortie
   fi
}
# fin préliminaire-------------------fonction : postliminaire-------------------------------
postliminaire()
{
   msg_final="::: Temps d'exécution : $(($SECONDS/3600)) heure(s), $(($SECONDS%3600/60)) minute(s) et $(($SECONDS%60)) seconde(s)"
   l_msg_final=${#msg_final}
   l_fichier_sortie=${#fichier_sortie}
if [ $fichier_sortie != /dev/null ] ; then
  if [ $option_csv == 1 ] ; then
     if ! [ -f $fichier_sortie.csv ] || ! [ -s $fichier_sortie.csv ] ; then
       echo -e "\n::: Le fichier '$fichier_sortie.csv' n'existe pas, ou il est vide." | tee -a $fichier_sortie
     else
       taille=$(ls -l $fichier_sortie.csv | awk -F" " '{print $5 " octets - " $6 " " $7 " " $8}')
       echo -e "\n::: Fichier $fichier_sortie.csv : créé ($taille)" | tee -a $fichier_sortie
     fi
  fi
  if [ $option_pdf == 1 ] ; then
     if ! [ -f $fichier_sortie.pdf ] || ! [ -s $fichier_sortie.pdf ] ; then
        type enscript &>/dev/null && type ps2pdfwr &>/dev/null
        if [ $? == 0 ]; then
           echo -e "\n::: Fichier $fichier_sortie.pdf : en cours de création ($(date  +%e" "%b" "%k:%M))" | tee -a $fichier_sortie
        else
           echo -e "\n::: Fichier '$fichier_sortie.pdf' non créé : manque 'enscript' et/ou 'ps2pdfwr'" | tee -a $fichier_sortie
       fi
     else
       taille=$(ls -l $fichier_sortie.pdf | awk -F" " '{print $5 " octets - " $6 " " $7 " " $8}')
       echo -e "\n::: Fichier $fichier_sortie.pdf : créé ($taille)" | tee -a $fichier_sortie
     fi
  fi
   if ! [ -f $fichier_sortie ] || ! [ -s $fichier_sortie ] ; then
      echo -e "\n::: Le fichier '$fichier_sortie' n'existe pas, ou il est vide." | tee -a $fichier_sortie
   else
     octets_sortie=$(wc -c < $fichier_sortie)
     l_octets_sortie=${#octets_sortie}
     l_total=$(( octets_sortie + l_fichier_sortie + l_msg_final + l_octets_sortie + l_octets + 53 ))
     taille=$(ls -l $fichier_sortie | awk -v N="$l_total" -F" " '{print N " octets - " $6 " " $7 " " $8}')
     echo -e "\n::: Fichier $fichier_sortie : créé ($taille)" | tee -a $fichier_sortie
  fi
fi
echo -e "\n$msg_final\n" | tee -a $fichier_sortie
if [ "$option_pdf" == "1" ] ; then
   mots2pdf "$@"
fi
}
# fin postliminaire -----------------fonction : petites fct suppression---------------------
  accent_capit="ÀÁÂĀÃÄÅĄÆÇČĎÐÈÉÊËĚÌÍÎĪÏÍŁÑŇÒÓÔŌÕÖØŒŘŠŞŤŢÙÚÛÜŮÝŸŶŽÞßẞ"
  accent_bdcas="àáâāãäåąæçčďđèéêëěìíîïīíłñňòóôōõöøœřšşťţùúûüůýÿŷžþßß"
   accent_tous="àáâāãäåąçčďđèéêëěìíîïīíłñňòóôōõöřšşťţùúûüůýÿŷžÀÁÂĀÃÄÅĄÇČĎÐÈÉÊËĚÌÍÎĪÏÍŁÑŇÒÓÔŌÕÖŘŠŞŤŢÙÚÛÜŮÝŸŶŽ"
no_accent_tous="aaaaaaaaccddeeeeeiiiiiilnnoooooorssttuuuuuyyyzAAAAAAAACCDDEEEEEIIIIIILNNOOOOOORSSTTUUUUUYYYZ"
# ---------
# note : que les fct aient le même nom que des variables n'est pas un problème
bas_de_casse()
{
   donnees=$(tr [A-Z] [a-z] <<< "$donnees")
   donnees=$(sed -E -e "y/$accent_capit/$accent_bdcas/" <<< $donnees)
}
# ---------
supp_diacritique()
{
   donnees=$(sed -E -e "y/$accent_tous/$no_accent_tous/" <<< $donnees)
}
# ---------
supp_punct()
{
   donnees=$(sed -E -e 's/ʾ|\x27|\xe2\x80\x99|“|”|%|‰|,|\.|\\|\/|\$|£|€|<|=|>|;|:|\(|\)|\[|\]|\{|\}|!|\?|\"|-|@|#|\*|_|\||§|&|~|\^|`|µ|\+|°|\xe2\x80\x93|−|«|»|½|¼|÷|×|¡|¿|…|·|²|³|®|±|\´|º|¥|©|¨|¾|¹|¸|ª|¦|¶|¤|¢|•/ /g' <<< $donnees)
   supp_ajout="supprimés "
}
# ---------
supp_chiffre()
{

   # donnees=$(sed 's/[0-9]//g' <<<$donnees)
   donnees=$(awk '{gsub("[0-9]", "")} ; Print $0' <<< $donnees)
}
# fin petite fct suppression----------fonction : syllabeur----------------------------------
syllabeur()
{
    trap 'setterm -cursor on;
       echo -e "\n" ;
       echo -e "::: Mots analysés : $nb_mots - Temps passé : $(($SECONDS/3600)) heure(s), $(($SECONDS%3600/60)) minute(s) et $(($SECONDS%60)) seconde(s)\n " ;
       exit' HUP INT
   echo "$(setterm -cursor off)"
   nb_total_mots=$(echo $donnees | sed 's/./&\n/g' | grep -c " ")
   nb_total_mots=$(($nb_total_mots +1))
   if [ $lister_liste == 1 ] ; then
      echo -e "::: Nombre de syllabes par mot" | tee -a $fichier_sortie
      echo -e "::: Rang;nombre;syllabes et symboles" | tee -a $fichier_sortie
   fi
   # les donnees sont réduites aux minuscules non accentuées. L'algorithme est adapté de
   # celui de Pailler [1999] qui porte sur les phonèmes et non sur les syllabes d'un texte
   donnees_ori=$donnees
   bas_de_casse
   supp_diacritique
   for mot in $donnees ; do
       sortie=$(awk ' BEGIN {
       FS=" ";
       OFS=" ";
       V="[aàâäeéèêëiïoôöuùûüyÿæœ]"; # toutes voyelles
       C="[bcçdfghjklmnpqrstvwxz-]"; # consonnes lato sensu
       }
       {
          n=1
          a=$n
          while (i=match(a, V C V)) {
             a=substr(a,1,i) "/" substr(a,i+1, length(a)); n++}
          while (i=match(a, V V V V)) {
             a=substr(a,1,i+1) "/" substr(a,i+2, length(a)); n++}
          while (i=match(a, V C V V)) {
             a=substr(a,1,i) "/" substr(a,i+1, length(a)); n++}
          while (i=match(a, C V C C V)) {
             a=substr(a,1,i+2) "/" substr(a,i+3, length(a)); n++}
          while (i=match(a, V C C V)) {
             a=substr(a,1,i+1) "/" substr(a,i+2, length(a)); n++}
          while (i= match(a, V C C C V)) {
             a=substr(a,1,i+1) "/" substr(a,i+2,length(a)); n++}
          while (i=match(a, V C C C C V)) {
             a=substr(a,1,i+1) "/" substr(a,i+2,length(a)); n++}
          while (i=match(a, V C C C C C V)) {
             a=substr(a,1,i+1) "/" substr(a,i+2,length(a)); n++}
          # compute the CVY skeleton
          sk= "";
          for (i=1;i<=length(a);i++) {
             ph=substr(a,i,1);
             if (ph~V) sk=sk"V";
             else if (ph~C) sk=sk"C";
             else sk=sk ph;
           }
       } { print "\n",n,a,sk } ;' <<< $mot) # fin de sortie=awk
       # formatage de la sortie
       sortie=$(echo $sortie | awk '{print " :::", $1, "=>", $2, "("$3")" }')
       nb_mots=$(($nb_mots + 1))
       if [ $lister_liste == 1 ] ; then
          echo $nb_mots" "$sortie | tee -a $fichier_sortie
       else
          tput sc
          echo -e -n "::: Calcul des syllabes. Ctrl-c pour interrompre. Mots analysés : $nb_mots (sur $nb_total_mots)"
          tput rc
       fi
       sortie2=$sortie2$sortie
   done
   # sortie de la grande boucle for mots in donnees ; on peut alors comptabiliser les syllabes
   sortie2=$(sed -e 's/:::/\n:::/g' <<< $sortie2)
   numcol=2
   nb_syllabes=$(awk -F ' ' -v champ="$numcol" '{ total += $champ } END {print total}' <<<$sortie2)
   # nb_m3_syllabes = nombre de mots de plus de trois syllabes
   nb_m3_syllabes=$(awk -F ' ' -v champ="$numcol" '{if($champ>3) {cpt+=1}} END {if (cpt) {print cpt} else {print 0}}' <<<$sortie2)
   if [ $lister_liste == 1 ] ; then
      echo | tee -a $fichier_sortie
      echo -e "::: Répartition des mots par nombre de syllabes" | tee -a $fichier_sortie
      echo -e "::: Rang;syllabes;nombre de mots" | tee -a $fichier_sortie
      for valeur in `seq 1 10` ; do
         compt=$(awk -F ' ' -v champ="$numcol" -v value="$valeur" '{if($champ==value) {cpt+=1}} END {print cpt}' <<<$sortie2 )
         if [ $compt ]; then
            let rang++
            echo -e "$rang ::: $valeur => $compt" | tee -a $fichier_sortie
         fi
      done
      echo -e "::: Nombre total de syllabes : $nb_syllabes" | tee -a $fichier_sortie
   fi
   donnees=$donnees_ori
   unset sortie sortie2 valeur numcol donnees_ori
   echo "$(setterm -cursor on)"
   trap "echo ;exit" HUP INT # retour à l'état par défaut
}
# fin syllabeur----------------------fonction : nb per mots---------------------------------
nb_per_mots()
{
   # Paramètre pour initialiser le script awk.
   compteur=0
   for lettre in $liste_mots
   do
      init_tab_awk="$init_tab_awk tab_jeton[${compteur}] =  \"$lettre\"; tab_nombre[${compteur}] = 0; tab_total[${compteur}] =  0 ;"
      # A passer comme paramètres au script awk ci-dessous.
      compteur=$(expr $compteur + 1)
   done
   # echo $init_tab_awk | sed 's/tab_jeton/\ntab_jeton/g' # pour debug
   awk \
   "BEGIN { $init_tab_awk } \
   { split(\$0, tab, \" \"); \
   for (caractere in tab) \
      { for (caractere2 in tab_jeton) \
         { if (tab_jeton[caractere2] == tab[caractere]) \
             { tab_nombre[caractere2]++ } \
             { tab_total[caractere2] = tab_total[caractere2 -1 ] + tab_nombre[caractere2] }  } } } \
   END { for (caractere in tab_nombre) \
      { print \"::: \" tab_nombre[caractere] \" => \" tab_jeton[caractere] } {print \"::: Total : \" tab_total[caractere]  } }" <<< $donnees
}
# fin nb_per_mots--------------------fonction : nb_per_char---------------------------------
nb_per_char()
{
   # Paramètre pour initialiser le script awk.
   compteur=0
   for lettre in $liste_car
   do
      init_tab_awk="$init_tab_awk tab_jeton[${compteur}] =  \"$lettre\"; tab_nombre[${compteur}] = 0; tab_total[${compteur}] =  0 ;"
      # A passer comme paramètres au script awk ci-dessous.
      compteur=$(expr $compteur + 1)
   done
   # echo $init_tab_awk | sed 's/tab_jeton/\ntab_jeton/g' # pour debug
   awk \
   "BEGIN { $init_tab_awk } \
   { split(\$0, tab, \"\"); \
   for (caractere in tab) \
      { for (caractere2 in tab_jeton) \
         { if (tab_jeton[caractere2] == tab[caractere]) \
             { tab_nombre[caractere2]++ } \
             { tab_total[caractere2] = tab_total[caractere2 -1 ] + tab_nombre[caractere2] }  } } } \
   END { for (caractere in tab_nombre) \
      { print \"::: \" tab_nombre[caractere] \" => \" tab_jeton[caractere] } {print \"::: Total : \" tab_total[caractere]  } }" <<< $donnees 2>/dev/null
}
# fin nb_per_char--------------------fonction : onyva---------------------------------------
onyva()
{
   data_a_analyser=$1
   liste=$2
   compteur=0
   for lettre in $(echo $liste)    # Pour chacune...
      do
         tableau_awk="$tableau_awk tab_lettre[${compteur}] = \"$lettre\"; tab_nombre[${compteur}] = 0; "
         # A passer comme paramètres au script awk ci-dessous.
         compteur=$(expr $compteur + 1)
      done
      # echo "TABLEAU_AWK :"$tableau_awk # Pour debug
   echo $data_a_analyser |
   awk \
   "BEGIN { $tableau_awk } \
      { split(\$0, tab, \"\"); \
      for (caractere in tab) \
         { for (caractere2 in tab_lettre) \
            { if (tab_lettre[caractere2] == tab[caractere]) { tab_nombre[caractere2]++ } } } } \
      END { for (caractere in tab_nombre)
          { total += tab_nombre[caractere] }
          { print total } } " 2>/dev/null
          # { print tab_lettre[caractere] tab_nombre[caractere] } } " # pour debug affichage après appel fct
}
# fin onyva -------------------------fonction : opérations monétaires-----------------------
operations_monetaires()
{
   # remplacement des espaces des expressions monétaires par des insécables fines
   esp_avant=$(echo $donnees | sed 's/./&\n/g' | grep -c " ")
   donnees=$(sed  -E -e 's/( |^)([0-9]{1,3}) ([0-9]{3}[^)($|[^0-9])/\1\2\xe2\x80\xaf\3/g' \
                     -e 's/([0-9]{3}) ([0-9]{3}[^)($|[^0-9])/\1\xe2\x80\xaf\2/g' \
                     -e 's/([0-9]{3}) ([0-9]{3}[^)($|[^0-9])/\1\xe2\x80\xaf\2/g' <<< $donnees)
   esp_apres=$(echo $donnees | sed 's/./&\n/g' | grep -c " ")
   esp_monetaires=$(($esp_avant - $esp_apres))
   # comptage  point et virgule monétaires
   pt_virg_monetaires=$(echo $donnees | sed -E -e 's/([0-9][\.,][0-9])/\1\n/g' | wc -l)
   pt_virg_monetaires=$(($pt_virg_monetaires -1))
}
# fin des opérations monétaires------fonction : filtrer-------------------------------------
filtrer()
{
donnees_int=$1
   # suppression des points sauf dans les nombres et les mots
   donnees_int=$(gawk '{ print gensub(/(^|[^[a-zA-Z0-9])\.+([^a-z]|$)/, "\\1 \\2", "g", $0) }' <<< $donnees_int)
   # suppression des virgules sauf dans les nombres (US style)
   donnees_int=$(gawk '{ print gensub(/(^|[^0-9]),+([^0-9]|$)/, "\\1 \\2", "g", $0) }' <<< $donnees_int)
   # suppression des points et virgules qui subsistent en fin de mot et de ligne
   donnees_int=$(gawk '{ print gensub(/(\.+|,+)([\x20\x0a\x0d\x0a]|$)+/, " ", "g", $0) }' <<< $donnees_int)
   # suppression des degrés sauf dans les nombres
   donnees_int=$(gawk '{ print gensub(/(^|[^0-9])°+([^0-9]|$)/, "\\1 \\2", "g", $0) }' <<< $donnees_int)
   # Suppression des slashs =sauf dans les nombres et les mots=
   donnees_int=$(gawk '{ print gensub(/(^| )\/+|\/+([^a-zA-Z0-9]|$)/, "\\1 \\2", "g", $0) }' <<< $donnees_int)
   # Suppression de % non suivi d'une espace
   donnees_int=$(gawk '{ print gensub(/(‰|%)([^ ]+)/, " \\2", "g", $0) }' <<< $donnees_int)
   # Suppression des % dont le prédécesseur n'est pas un nombre avec ou sans espace
   donnees_int=$(gawk '{ print gensub(/([^0-9 ])(%|‰)/, "\\1 ", "g", $0) }' <<< $donnees_int)
   # Suppression du reste des % sans toucher aux formes conservées type 12,5% ou 12 %
   donnees_int=$(gawk '{ print gensub(/([^0-9] )[%|‰]( )/, "\\1\\2", "g", $0) }' <<< $donnees_int)
   # Remplacement des espaces par des insécables fines  pour les % et les glyphes monétaires
   donnees_int=$(gawk '{ print gensub(/([0-9])( )([$€¥£%‰])/, "\\1\xe2\x80\xaf\\3", "g", $0) }' <<< $donnees_int)
   # Suppression des glypes monétaires isolés
   donnees_int=$(gawk '{ print gensub(/([^0-9] )[$£€¥]+( |$)/, "\\1\\2", "g", $0) }' <<< $donnees_int)
   # Reste des autres suppressions
   donnees_int=$(gawk '{ print gensub(/\xe2\x80\x99{2,}|ʾ| \xe2\x80\x99|\xe2\x80\x99 |“|”|<|=|>|;|:|\(|\)|\[|\]|\{|\}|!|\?|"| -|- |-{2,}|@|#|\*/, " ", "g", $0) }' <<< $donnees_int)
   donnees_int=$(gawk '{ print gensub(/ _|_ |_{2,}|\||§|&|~|\^|`|µ|\+|\xe2\x80\x93|−|«|»|½|¼|÷|×|¡|¿|…|·|²|³|®|±|\\´|º|©|¨|¾|¹|¸|ª|¦|¶|¤|¢|•/, " ", "g", $0) }' <<< $donnees_int)
   # suppression apostrophe x27 sauf dans les mots
   donnees_int=$(gawk '{ print gensub(/([[:space:]][\x27]|[[:punct:]][\x27]|[\x27][[:space:]]|[\x27][[:punct:]])/, " ", "g", $0) }' <<<$donnees_int)
   donnees_int=$(gawk '{ print gensub(/([^[:alnum:]][\x27]|[\x27]$)/, " ", "g", $0) }' <<< $donnees_int)
}
# fin filtrer------------------------fonction : analyse par mots commun---------------------
analyse_par_mots_commun()
{
   # dans la fonction set -f supprime l'expansion des * en directory
   set -f
   if [ $type_entree == directe ]; then
      octets=$(wc -c < "$objet")
      total_lignes=$(sed -n -e '$=' "$objet")
      vides=$(grep -c -E "^[[:space:]]*$" "$objet")
  else
      octets=$(wc -c <<< "$donnees_brutes")
      total_lignes=$(sed -n -e '$=' <<< $donnees_brutes)
      vides=$(grep -c -E "^[[:space:]]*$" <<< "$donnees_brutes")
   fi
   if [ $pleines -gt $espaces ] ; then
      type="liste"
      if [ $option_syllabeur == 1 ] ; then
         echo -e "\n::: La syllabation n'est pas mise en oeuvre pour les listes"
      fi
      # acquisition des données avec remplacement des espaces par des tildes (ou insécables normales)
      # donnees=$(cat "$objet" | sed 's/\r//' | sed -e 's/ /\xc2\xa0/g')
      donnees=$(echo "$donnees_brutes" | sed 's/\r//' | tr ' ' '~')
      # passage de iconv (ne convertit pas les CR LF FF)
      donnees=$(iconv -c -f $char_set -t utf-8 <<< $donnees)
      if [ "$bas_de_casse" == "1" ];then
         bas_de_casse
         echo "::: Réduction des capitales en bas-de-casse" | tee -a $fichier_sortie
      fi
      if [ "$supp_diacritique" == "1" ];then
         supp_diacritique
         echo "::: Réduction des diacritiques en lettres simples" | tee -a $fichier_sortie
      fi
      if [ "$supp_chiffre" == "1" ];then
         echo "::: L'option suppression des chiffres ne s'applique pas aux listes"
         supp_chiffre=0
      fi
      if [ "$supp_punct" == "1" ];then
         echo "::: L'option suppression de la ponctuation ne s'applique pas aux listes"
         supp_punct=0
      fi
   else
      type="texte"
      # copie fichier avec substitution des \ par #, et CR LF et FF  ce qui ne change rien ensuite aux comptages
      donnees=$(echo $donnees_brutes | tr '\n\r\f' ' ' | tr '\\' '#')
      # passage iconv (ne convertit pas les CR LF FF)
      donnees=$(iconv -c -f $char_set -t utf-8 <<< $donnees)
      liste1='\x27 \xe2\x80\x99 ! \" #  “ ” % ‰ & ( ) \* + , - . / : ; < = > ? @ [ \\ ] ^ _ ` { | } ~ ¡ § « ° » ¿ ÷ × − – $ £ € ½ ¼ ʾ µ …  · ² ³ ® ± ´ º ¥ © ¨ ¾ ¹ ¸ ª ¦ ¶ ¤ ¢ •'
      nb_total_punct=$(onyva "$donnees" "$liste1")
      if [ -z $nb_total_punct ] ; then
         usage
         echo -e "::: Ligne ${LINENO} : variable 'nb_total_punct' non définie. Abandon\n" | tee -a $fichier_sortie
         echo -e "::: Temps passé : $(($SECONDS/3600)) heure(s), $(($SECONDS%3600/60)) minute(s) et $(($SECONDS%60)) seconde(s)\n " | tee -a $fichier_sortie
         exit
      fi
      nb_total_phrases=$(echo $donnees | sed -E -e  's/[.!?](\x20|$)/A9B8C7D6\n/g' | grep -c A9B8C7D6)
      if [ $nb_total_phrases == 0 ] ; then
         nb_total_phrases=1
      fi
      if [ $option_monetaire == 1 ]; then
         operations_monetaires
      fi
      if [ "$supp_chiffre" == "1" ];then
         supp_chiffre
         echo "::: Suppression des chiffres" | tee -a $fichier_sortie
      fi
      filtrer "$donnees"
      donnees=$donnees_int
      unset donnees_int
      liste3="- _ . , / ' \xe2\x80\x99 $ £ € ¥ ° % ‰"
      nb_punct_dans_mots=$(onyva "$donnees" "$liste3")
      liste4="\xc2\xa0 \xe2\x80\xaf"
      nb_total_insecables=$(onyva "$donnees" "$liste4")
      if [ "$bas_de_casse" == "1" ];then
         bas_de_casse
         echo "::: Réduction des capitales en bas-de-casse" | tee -a $fichier_sortie
      fi
      if [ "$supp_diacritique" == "1" ];then
         supp_diacritique
         echo "::: Réduction des diacritiques en lettres simples" | tee -a $fichier_sortie
      fi
      if [ "$supp_punct" == "1" ];then
         supp_punct
         echo "::: Suppression de la ponctuation" | tee -a $fichier_sortie
      fi
      if [ "$option_syllabeur" == "1" ] && ! [ "$syllabeur_fait" == "1" ] ;then
         syllabeur
         syllabeur_fait=1
      fi
   fi
}
# fin analyse par mots commun--------fonction : analyse par mots détail---------------------
analyse_par_mots_detail()
{
   # copie de donnees de chaîne en tableau temporaire
   donnees_tab=( $donnees )
   if [ $lister_m_texte == 1 ] && [ $lister_liste == 1 ]; then
      echo | tee -a $fichier_sortie
      echo -e "::: Taille des mots" | tee -a $fichier_sortie
      echo "::: Rang;longueur en lettres;mot" | tee -a $fichier_sortie
   fi
   # avec LC_ALL=C, ${#donnees_tab[i]} compte les octets et non les caractères
   unset LC_ALL
   for i in ${!donnees_tab[@]} ; do
      long="${#donnees_tab[i]}"
      car_in_mots=$(($car_in_mots + $long))
      if [ $lister_m_texte == 1 ] && [ $lister_liste == 1 ] ; then
         echo $(($i +1)) "::: $long => ${donnees_tab[$i]}"
         if ! [ "$fichier_sortie" == "/dev/null" ]; then
            echo $(($i +1)) "::: $long => ${donnees_tab[$i]}" >> $fichier_sortie
         fi
         sortie=$sortie" "$long
      fi
   done
   LC_ALL=C
   unset donnees_tab
   # on peut faire le calcul de la répartition des mots par nombre de lettres
   if [ $lister_m_texte == 1 ] && [ $lister_liste == 1 ] ; then
      echo -e "\n::: Répartition des mots par nombre de lettres" | tee -a $fichier_sortie
      echo -e "::: Rang;longueur en lettres; nombre de mots" | tee -a $fichier_sortie
      rang=0
      sortie=$(sed -e 's/ /\n/g' <<< $sortie)
      for valeur in $(seq 1 124) ; do
         compt=$(awk -F ' ' -v value="$valeur" '{if($1 == value) {cpt+=1}} END {print cpt}' <<< "$sortie" )
         if [ $compt ] ; then
            let rang++
            pourcent=$( echo "scale=2; $compt*100/$(($i + 1))" | bc -l )
            echo -e "$rang ::: $valeur => $compt soit $pourcent %" | tee -a $fichier_sortie
         fi
      done
   fi
   nb_mots=$(($i + 1))
   if [ $car_in_mots -gt 0 ]; then
      moy_car=$(echo "scale=5; $car_in_mots/$nb_mots" | bc -l)
   else
      moy_car=0
      nb_mots=0
   fi
   if [ $type == texte ]; then
      autres=$(($nb_total_punct - $nb_punct_dans_mots))
      moy_phrase=$(echo "scale=5; $nb_mots/$nb_total_phrases" | bc -l)
      complexite=$(echo "scale=5; ($moy_car - 4.2 + 7*l($moy_phrase) - 8)/1.2" | bc -l)
      coleman=$(echo "scale=5; (5.88*$moy_car - 0.296*(100/$moy_phrase) - 15.8)" | bc -l)
      ari=$(echo "scale=5; (4.71*$moy_car + 0.5*$moy_phrase - 21.43)" | bc -l)
      # après calcul on limite le nb de décimales, mais printf depend de la locale séparateur
      # et LANG=C ou LC_NUMERIC=C ne marchent pas sur toutes les distributions
      moy_car_=$(printf "%.2f\n" "$moy_car" 2>/dev/null)
      if [ $? == 1 ] ; then
         moy_car=${moy_car/./,}
         moy_phrase=${moy_phrase/./,}
         complexite=${complexite/./,}
         coleman=${coleman/./,}
         ari=${ari/./,}
         moy_car_=$(printf "%.2f\n" "$moy_car")
      fi
      moy_car=${moy_car_/,/.}
      moy_phrase_=$(printf "%.2f\n" "$moy_phrase")
      moy_phrase=${moy_phrase_/,/.}
      complexite=$(printf "%.2f\n" "$complexite")
      complexite=${complexite/,/.}
      coleman=$(printf "%.2f\n" "$coleman")
      coleman=${coleman/,/.}
      ari=$(printf "%.2f\n" "$ari")
      ari=${ari/,/.}
      if [ $option_syllabeur == 1 ] ;then
         flesh_1=$(echo "scale=5; 206.835 - 1.015*($nb_mots/$nb_total_phrases) - 84.6*($nb_syllabes/$nb_mots)" | bc -l)
         flesh_2=$(echo "scale=5; 0.39*($nb_mots/$nb_total_phrases) + 11.8*($nb_syllabes/$nb_mots) - 15.59" | bc -l)
         gunning=$(echo "scale=5; 0.4*(($nb_m3_syllabes*100/$nb_mots) + $moy_phrase)" | bc -l)
         smog=$(echo "scale=5; 1.0430*(sqrt($nb_m3_syllabes*30/$nb_total_phrases)) + 3.1291" | bc -l)
         flesh_1_=$(printf "%.2f\n" "$flesh_1" 2>/dev/null)
         if [ $? == 1 ] ;then
            flesh_1=${flesh_1/./,}
            flesh_1_=$(printf "%.2f\n" "$flesh_1")
            flesh_2=${flesh_2/./,}
            gunning=${gunning/./,}
            smog=${smog/./,}
         fi
         flesh_1=${flesh_1_/,/.}
         flesh_2=$(printf "%.2f\n" "$flesh_2")
         flesh_2=${flesh_2/,/.}
         gunning=$(printf "%.2f\n" "$gunning")
         gunning=${gunning/,/.}
         smog=$(printf "%.2f\n" "$smog")
         smog=${smog/,/.}
         moy_indices=$(echo "scale=2; ($complexite+$coleman+$ari+$flesh_2+$gunning+$smog)/6" | bc -l)
      fi
   fi
   echo -e "\n::: Analyse du détail des mots :::" | tee -a $fichier_sortie
   echo -e "$donnees_source$ligne_cmd_ori | Type : $type | Charset : $char_set | Octets : $octets" | tee -a $fichier_sortie
   if [ $type == texte ]; then
      echo "::: Lignes : $total_lignes | Dont vides : $vides | Espaces sécables : $espaces | Autres car. impr. $supp_ajout: $autres"  | tee -a $fichier_sortie
      echo "::: Nombre de mots : $nb_mots | Nombre de caractères de toute nature : "$(($total_lignes + $car_in_mots + $espaces + $autres)) | tee -a $fichier_sortie
      echo "::: Nombre de caractères composant les mots : $car_in_mots | Dont insécables : $nb_total_insecables | Dont ponct. : $nb_punct_dans_mots" | tee -a $fichier_sortie
      if [ $option_monetaire == 1 ]; then
         echo "::: Espaces monetaires remplacés : $esp_monetaires | Points et virgules monetaires inclus en mots : $pt_virg_monetaires" | tee -a $fichier_sortie
      fi
      if [ $option_syllabeur == 1 ]; then
         echo "::: Longueur moyenne des mots : $moy_car caractères | Syllabes : $nb_syllabes" | tee -a $fichier_sortie
      else
         echo "::: Longueur moyenne des mots : $moy_car caractères" | tee -a $fichier_sortie
      fi
      echo "::: Nombre de phrases : $nb_total_phrases | Longueur moyenne des phrases : $moy_phrase mots" | tee -a $fichier_sortie
      echo "::: Indice de lisibilité spécifique : "$complexite | tee -a $fichier_sortie
      echo "::: Indice de Coleman-Liau : $coleman - Indice ARI : $ari "| tee -a $fichier_sortie
      if [ $option_syllabeur == 1 ]; then
         echo -e "::: Indice Flesh-Kincaid général : $flesh_1 - Flesh-Kincaid niveau d'éducation : $flesh_2" | tee -a $fichier_sortie
         echo -e "::: Indice Gunning-Fog : $gunning - Indice SMOG : $smog - Moyenne des indices éducation : $moy_indices" | tee -a $fichier_sortie
      fi
   else
      echo "::: Caractères composant les mots : $car_in_mots | Dont espaces sécables : $espaces" | tee -a $fichier_sortie
      echo "::: Mots : $nb_mots | Lignes : $total_lignes | Dont vides : $vides" | tee -a $fichier_sortie
      moy_car_=$(printf "%.2f\n" "${moy_car/./,}" 2>/dev/null)
      if [ $? == 1 ] ; then
         moy_car=$(printf "%.2f\n" "${moy_car/,/.}")
      else
         moy_car=$(printf "%.2f\n" "${moy_car/./,}")
      fi
      moy_car=${moy_car/,/.}
      echo "::: Longueur moyenne des mots : $moy_car caractères" | tee -a $fichier_sortie
   fi
   echo "::: ----------------------------------------------------------------------------" | tee -a $fichier_sortie
}
# fin analyse par mots détail--------fonction : analyse par caractères------------------------
analyse_par_caracteres()
{
   set -f
   # Suppression de CR LL FF non breaking space normal et fine
   donnees=$(gawk '{ print gensub(/[\x0a\x0d\x0c\xc2\xa0\xe2\x80\xaf]/, " ", "g", $0) }' <<< $donnees_brutes)
   # passage iconv (ne convertit pas les CR LF FF)
   donnees=$(iconv -c -f $char_set -t utf-8 <<< $donnees)
   echo | tee -a $fichier_sortie
      if [ "$supp_chiffre" == "1" ];then
         supp_chiffre
         echo "::: Suppression des chiffres c" | tee -a $fichier_sortie
      fi
      if [ "$bas_de_casse" == "1" ];then
         bas_de_casse
         echo "::: Réduction des capitales en bas-de-casse c" | tee -a $fichier_sortie
      fi
      if [ "$supp_diacritique" == "1" ];then
         supp_diacritique
         echo "::: Réduction des diacritiques en lettres simples c" | tee -a $fichier_sortie
      fi
      if [ "$supp_punct" == "1" ];then
         supp_punct
         echo "::: Suppression de la ponctuation c" | tee -a $fichier_sortie
      fi
   # établissement ici de la liste des caractères des données à analyser. Le découpage en tranches
   # est  destiné à prévenir la 'génération spontanée' de caractères corrompus de type ef bf bd
   nb_mots_1=$(echo $donnees | sed 's/./&\n/g' | grep -c " ")
   nb_mots_1=$(($nb_mots_1 + 1))
   passe=$(($nb_mots_1 / 10000 + 1 ))
   debut=1
   pas=9999
   i=0
   while [ "$i" -lt "$passe" ] ; do
      i=$(($i + 1))
      liste_car_=$(echo $donnees | cut -f $debut-$(($debut + $pas)) --delimiter=" ")
      liste_car_=$(gawk '{ print gensub(/(.?)/, "\\1\n", "g", $0) }' <<< $liste_car_)
      liste_car_=$(gawk '{ print gensub(/( )/, "\\1\x0a", "g", $0) | "sort -u" }' <<< $liste_car_)
      # indispensable antislashage de \ (pas évident) ` et "
      liste_car_=$(gawk '{ print gensub(/(\\)/, "\\1\\1", "g", $0) }' <<< $liste_car_)
      liste_car_=$(gawk '{ print gensub(/`/, "\\\\`", "g", $0) }' <<< $liste_car_)
      liste_car_=$(gawk '{ print gensub(/(")/, "\\\\\\1", "g", $0) }' <<< $liste_car_)
      liste_car_=$(echo ${liste_car_:1})
      liste_car="$liste_car $liste_car_"
      liste_car=$(echo $liste_car | sed -e 's/ /\n/g' | sort -u)
      debut=$(($debut + $pas +1))
   done
   l_liste_tmp=$(echo $liste_car | sed 's/./&\n/g' | grep -c " ")
   l_liste_tmp=$(($l_liste_tmp + 1))
   # la fct nb_per_char retourne les caractères de $liste_car présents dans $donnees avec leur nombre
   resultats=$(nb_per_char)
   # nb_char_dans_car est la somme des nombres des caractères listés
   nb_chars_dans_car=$(echo $resultats | sed -E -e 's/.*Total : //g')
   # le test suivant prévient notamment des dépassements de mémoire
   if [ -z $nb_chars_dans_car ] ; then
      usage
      echo -e "::: Ligne ${LINENO} : variable 'nb_total_punct' non définie. Abandon\n" | tee -a $fichier_sortie
      echo -e "::: Temps passé : $(($SECONDS/3600)) heure(s), $(($SECONDS%3600/60)) minute(s) et $(($SECONDS%60)) seconde(s)\n " | tee -a $fichier_sortie
      exit
   fi
   echo -e "\n::: Analyse des caractères :::" | tee -a $fichier_sortie
   if [ $lister_c_alpha == 1 ] && [ $lister_liste == 1 ] ; then
      echo -e "::: Caractères comptabilisés : "$liste_car | tee -a $fichier_sortie
      echo -e "::: Fréquence des caractères (par ordre alphabétique)" | tee -a $fichier_sortie
      echo -e "::: Rang;fréquence;caractère" | tee -a $fichier_sortie
      resultats=$(sort -t " " -k 4b,4 -k 2rn,2 <<< $resultats)
      resultats=$(sed -E -e '/Total.*$/d' <<< sed -E -e '/^ $/d' <<< $resultats)
      awk -v awk_local=$nb_chars_dans_car 'CONVFMT = "%.2f" {print $1,$2,$3,$4, "soit " $2*100/awk_local, "%"}' <<< $resultats | nl | sed -E -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
   fi
   if [ $lister_c_freq == 1 ] && [ $lister_liste == 1 ] ; then
      if [ $lister_c_alpha == 1 ] ; then echo ; fi | tee -a $fichier_sortie
      echo -e "::: Caractères comptabilisés : "$liste_car | tee -a $fichier_sortie
      echo -e "::: Fréquence des caractères (par ordre décroissant des fréquences)" | tee -a $fichier_sortie
      echo -e "::: Rang;fréquence;caractère" | tee -a $fichier_sortie
      resultats=$(sort -t " " -k 2rn,2 -k 4b,4 <<< $resultats)
      resultats=$(sed -E -e '/Total.*$/d' <<< sed -E -e '/^ $/d' <<< $resultats)
      awk -v awk_local=$nb_chars_dans_car 'CONVFMT = "%.2f" {print $1,$2,$3,$4, "soit " $2*100/awk_local, "%"}' <<< $resultats | nl | sed -E -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
   fi
   echo -e "\n::: Analyse des caractères :::" | tee -a $fichier_sortie
   echo -e "$donnees_source$ligne_cmd_ori " | tee -a $fichier_sortie
   echo -e "::: Nombre de caractères (espaces non compris) : "$l_liste_tmp | tee -a $fichier_sortie
   echo -e "::: Nombre d'occurrences de ces caractères : "$nb_chars_dans_car | tee -a $fichier_sortie
   echo "::: ---------------------------------------------------------------------------" | tee -a $fichier_sortie
}
# fin analyse par caractères---------fonction : affichage fréquence-------------------------
affichage_frequence()
{
   taux_h=$(echo "scale=5; $hapax*100/$nb_mots_1" | bc -l)
   taux_h_=$(printf "%.2f\n" "$taux_h" 2>/dev/null)
   if [ $? == 1 ] ; then
      taux_h=${taux_h/./,}
      taux_h_=$(printf "%.2f\n" $taux_h)
   fi
   taux_h=${taux_h_/,/.}
   taux_u=$(echo "scale=5; $nb_mots_1*100/$nb_mots_avant" | bc -l)
   taux_u_=$(printf "%.2f\n" "$taux_u" 2>/dev/null)
   if [ $? == 1 ] ; then
      taux_u=${taux_u/./,}
      taux_u_=$(printf "%.2f\n" $taux_u)
   fi
   taux_u=${taux_u_/,/.}
   echo -e "\n::: Analyse de la fréquence des mots :::" | tee -a $fichier_sortie
   echo -e "$donnees_source$ligne_cmd_ori" | tee -a $fichier_sortie
   echo -e "::: Nombre de mots "$donnees_origine ": $nb_mots_avant" | tee -a $fichier_sortie
   echo -e "::: Nombre de mots du vocabulaire $du_fichier_fourni: $nb_mots_1 - Taux vocabulaire/total : $taux_u %" | tee -a $fichier_sortie
   if [ $nb_mots_xx != 0 ] ; then
      echo -e "::: Nombre de mots $deplus : $nb_mots_xx" | tee -a $fichier_sortie
   fi
   echo -e "::: Nombre d'hapax $deplus: $hapax - Taux hapax/vocabulaire : $taux_h %" | tee -a $fichier_sortie
   echo -e "::: Indice de Gini : $indice_gini - Indice de Gini hors hapax : $indice_gini_h"| tee -a $fichier_sortie
   echo -e "::: Indice de Shannon : $indice_shannon - Indice de Simpson : $indice_simpson"| tee -a $fichier_sortie
   echo "::: ---------------------------------------------------------------------------" | tee -a $fichier_sortie
}
# fin affichage fréquence------------fonction : calcul variable temporaire-----------------
calcul_variable_temp()
{
# cette fonction établit variable_temp pour tous les traitements.
nb_mots_1=$(echo $liste_mots_1 | sed 's/./&\n/g' | grep -c " ")
nb_mots_1=$(($nb_mots_1 + 1))
passe=$(($nb_mots_1 / 1000 + 1 ))
debut=1
pas=999
i=0
while [ "$i" -lt "$passe" ] ; do
   i=$(($i + 1))
   echo -e "::: $(date '+%H:%M:%S') - Passe $i sur $passe"
   liste_mots=$(echo $liste_mots_1 | cut -f $debut-$(($debut + $pas)) --delimiter=" ")
   resultats=$(nb_per_mots)
   # echo $resultats | sed 's/:::/\n:::/g'
   variable_boucle=$(echo $resultats | sed 's/:::/\n:::/g' | sed 's/ $//g')
   debut=$(($debut + $pas +1 ))
   variable_tmp=("$variable_tmp $variable_boucle")
done
variable_temp=${variable_tmp[*]}
unset passe debut pas i variable_tmp variable_boucle
}
# fin calcul variable temporaire-----fonction : calcul des indices -----------------------
calcul_indice()
{
   if [ "$2" == "supp_l1" ]; then
      variable_indice=$(sed '1d' <<< $1)
   else
      variable_indice=$1
   fi
   variable_indice=$(echo -e "$variable_indice" | sed '/Total/d')
   # l'entropie ne supporte pas les occurrences nulles
   variable_shannon=$(grep -v "::: 0 =>" 2>/dev/null <<< $variable_indice)
   if [ -n "$variable_shannon" ] ; then
      indice_shannon=$(awk -v N=$nb_mots_avant -v S=$nb_mots_1 ' { B=$2 } ; { if (N!=1 && S!=1) {H += ((B/N)*log(B/N))/log(S)} else H = -0} ; \
          END { if (N!=1) {printf "%.4f\n", -H} else printf "%s\n", "non calculable"}' <<< $variable_shannon )
   else
      indice_shannon="non calculable"
   fi
   indice_simpson=$(awk -v N=$nb_mots_avant ' { A += $2*($2-1) } ; { if (N!=1) B = N*(N-1)} ; {if (N!=1) D = 1-(A/B)} ;  \
          END { if (N!=1) {printf "%.4f\n", D} else printf "%s\n", "non calculable"}' <<< $variable_indice)
   variable_gini=$(echo -e "$variable_indice" | sort -n -k 2 | nl )
   indice_gini=$(awk '{A += $1*$3} ; {B += $3} ; END  {if (B != 0) {printf "%.4f\n", 1-((2*A)/(NR*B)-(NR+1)/(NR))} else printf "%s\n", "non calculable"}' <<< $variable_gini)

   variable_gini_h=$(awk '$2 != "1" {print}'  <<< $variable_indice)
   variable_gini_h=$(echo -e "$variable_gini_h" | sort -n -k 2 | nl )
   indice_gini_h=$(awk '{A += $1*$3} ; {B += $3} ; END  {if (B != 0) {printf "%.4f\n", 1-((2*A)/(NR*B)-(NR+1)/(NR))} else printf "%s\n", "non calculable"}' <<< $variable_gini_h)
}
# fin calcul indices-----------------fonction : analyse de la frequence des mots-----------
analyse_par_mots_frequence()
{
   # établissement de la liste des mots index à appliquer aux données à analyser
   nb_mots_avant=$(echo $donnees | sed 's/./&\n/g' | grep -c " " 2>/dev/null)
   nb_mots_avant=$(($nb_mots_avant +1))
   echo -e "\n::: Analyse de la fréquence des mots :::" | tee -a $fichier_sortie
   # on sépare les cas fichier fourni ou non
   # on traite les deux cas de demande de frequence du texte ou xxx
   if [[ $lister_f_alpha == "1" || $lister_f_freq == "1" || $lister_x_alpha == "1" || $lister_x_freq == "1" ]] ; then
      if [ $type_entree == directe ];then
         echo -e "::: les mots indexés sont ceux du fichier analysé" | tee -a $fichier_sortie
      else
         echo -e "::: les mots indexés sont ceux du flux pipé ou redirigé" | tee -a $fichier_sortie
      fi
      # liste_mots_1 est la liste des mots singuliers provenant du texte
      liste_mots=$(awk "BEGIN { $tableau_awk } { split(\$0, tab, \" \"); for (mots in tab) { print tab[mots] } }" <<< $donnees )
      liste_mots_1=$(echo $liste_mots | tr ' ' '\n' | sort -u)
      # lister_i_alpha pour eviter edition indue dans la fonction lors d'un appel avant fichier_fourni
      if [ $lister_i_alpha == 1 ] ; then
         lister_i_alpha=0
         lister_i_alpha_tmp=1
      fi

      calcul_variable_temp
      calcul_indice "$variable_temp" "supp_l1"

      hapax=$(echo "$variable_temp" | grep "::: 1 " 2>/dev/null | wc -l)
      if [ $lister_i_alpha_tmp == 1 ] ; then
         lister_i_alpha=1
      fi

      if [ $lister_f_alpha == "1" ] && [ $lister_liste == 1 ] ; then
         # sortie triée dans l'ordre alphabétiuqe
         echo -e "\n::: Fréquence des mots (par ordre alphabétique)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         variable_temp=$(sort -t " " -k 4b,4 -k 2rn,2 <<< $variable_temp)
         variable_temp=$(echo "$variable_temp" | sed -E -e '/::: Total : .*$/d' | sed -E -e '/^ $/d')
         echo "$variable_temp" | nl | sed -E -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      fi # lister f alpha

      if [ $lister_f_freq == "1" ] && [ $lister_liste == 1 ] ; then
         # sortie triée dans l'ordre des fréquences
         echo -e "\n::: Fréquence des mots (par ordre décroissant des fréquences)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         variable_temp=$(sort -t " " -k 2rn,2 -k 4b,4 <<< $variable_temp)
         variable_temp=$(echo "$variable_temp" | sed -E -e '/::: Total : .*$/d' | sed -E -e '/^ $/d')
         echo "$variable_temp" | nl | sed -E -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      fi # lister f fréquence

      if [ $lister_f_alpha == "1" ] || [ $lister_f_freq == "1" ] ; then
         deplus=""
         affichage_frequence
      fi

      if [ $lister_x_alpha == "1" ] || [ $lister_x_freq == "1" ] ; then
         # on traite ensuite le cas de sortie -x=
         variable_temp=$(echo "$variable_temp" | sed -E -e '/::: Total : .*$/d' | sed -E -e '/^ $/d')
         echo -e "\n::: Mots du texte analysé de$plus $yyy lettre(s) de plus grande fréquence ($xxx demandés) :::" | tee -a $fichier_sortie
         if [ $egalite -eq 0 ] ; then
            variable_temp=$(awk -v yyy_awk=$yyy '{if (length($4) > yyy_awk) print $0 }' <<< $variable_temp)
         else
            variable_temp=$(awk -v yyy_awk=$yyy '{if (length($4) == yyy_awk) print $0 }' <<< $variable_temp)
         fi
         variable_temp_alpha=$(echo "$variable_temp" | sort -t" " -k 2rn,2 -k 4b,4 | sed -n '1, '$xxx' p'| sort -t" " -k 4b,4 -k 2rn,2 )
         variable_temp_freq=$(echo "$variable_temp" | sort -t" " -k 2rn,2 -k 4b,4 | sed -n '1, '$xxx' p')
         nb_mots_xx=$(echo "$variable_temp_alpha" | wc -l)
         hapax=$(echo "$variable_temp_alpha" | grep "::: 1 " | wc -l)
         if [ ${#variable_temp_alpha} == 0 ] && [ ${#variable_temp_freq} == 0 ] ; then
            echo -e "::: Aucun mot ne correspond à votre requête."
         else
            calcul_indice "$variable_temp_freq"
         fi
      fi

      if [ $lister_x_alpha == 1 ] && [ $lister_liste == 1 ] ; then
         echo -e "\n::: Fréquence des mots (par ordre alphabétique)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         echo "$variable_temp_alpha" | nl | sed -E -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      fi # option lister x alpha

      if [ $lister_x_freq == 1 ] && [ $lister_liste == 1 ] ; then
         echo -e "\n::: Fréquence des mots (par ordre décroissant des fréquences)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         echo "$variable_temp_freq" | nl | sed -E -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      fi # option lister x freq

      if [ $lister_x_alpha == "1" ] || [ $lister_x_freq == "1" ] ; then
         deplus="de$plus $yyy lettres "
         affichage_frequence
      fi
      unset variable_temp variable_temp_alpha variable_temp_freq variable_boucle
   fi # fin deux cas texte ou xxx

   # on traite alors l'option fichier fourni
   if [[ $lister_i_alpha == "1" || $lister_i_freq == "1" ]] ; then
      echo -e "\n::: les mots indexés proviennent du fichier '$fichier_fourni'" | tee -a $fichier_sortie
      # Liste_mots_1 fournie. On traite le charcet et on la nettoie
      liste_mots_1=$(cat $fichier_fourni)
      if [ $char_set_i ] ; then
         char_set_fichier_fourni=$char_set_i
      else
         char_set_fichier_fourni=$(file -i "$fichier_fourni" | sed -e "s/.*charset=//")
         if [ "$char_set_fichier_fourni" == "unknown-8bit" ]; then
            echo -e "\n::: Le charset de $fichier_fourni est inconnu. Forcé à ISO_8859-1, il peut être"
            echo -e "::: nécessaire de le redéfinir en cas d'échec de iconv ou de résultats aberrants"
            char_set_fichier_fourni=ISO_8859-1
         fi
      fi
      liste_mots_1=$(iconv -c -f $char_set_fichier_fourni -t utf-8 <<< $liste_mots_1)
      # ici il est plus simple de ne pas passer par une fct pour les suppressions
      if [ "$supp_chiffre_i" == "1" ] ; then
          liste_mots_1=$(tr -d [:digit:] <<< $liste_mots_1)
      fi
      filtrer "$liste_mots_1"
      liste_mots_1=$donnees_int
      unset donnees_int
      if [ "$bas_de_casse_i" == "1" ] ; then
         liste_mots_1=$(tr [A-Z] [a-z] <<< $liste_mots_1 )
         liste_mots_1=$(sed -E -e "y/$accent_capit/$accent_bdcas/" <<< $liste_mots_1)
      fi
      if [ "$supp_diacritique_i" == "1" ] ; then
         liste_mots_1=$(sed -E -e "y/$accent_tous/$no_accent_tous/" <<< $liste_mots_1)
      fi
      # on trie ne fût-ce que pour éliminer les doublons saisis
      liste_mots_1=$(echo $liste_mots_1 | tr '\n\r\f' ' ' | sed -E -e 's/ /\n/g' | sort -u)
      calcul_variable_temp
      calcul_indice "$variable_temp" "supp_l1"
      hapax=$(echo "$variable_temp" | grep "::: 1 " | wc -l)
      du_fichier_fourni="du fichier $fichier_fourni "
      if [ $lister_i_freq == "1" ] && [ $lister_liste == 1 ] ; then
         # sortie triée dans l'ordre des fréquences
         echo -e "\n::: Fréquence des mots (par ordre décroissant des fréquences)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         variable_temp=$(sort -t " " -k 2rn,2 -k 4b,4 <<< $variable_temp)
         variable_temp=$(echo "$variable_temp" | sed -E -e '/::: Total : .*$/d' | sed -E -e '/^ $/d')
         echo "$variable_temp" | nl | sed -E -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      fi # lister fréquence

      if [ $lister_i_alpha == "1" ] && [ $lister_liste == 1 ] ; then
         # sortie triée dans l'ordre alphabétique
         echo -e "\n::: Fréquence des mots (par ordre alphabétique)" | tee -a $fichier_sortie
         echo -e "::: Rang;fréquence;mot" | tee -a $fichier_sortie
         variable_temp=$(sort -t " " -k 4b,4 -k 2rn,2 <<< $variable_temp)
         variable_temp=$(echo "$variable_temp" | sed -E -e '/::: Total : .*$/d' | sed -E -e '/^ $/d')
         echo "$variable_temp" | nl | sed -E -e 's/^\s*([0-9]*)\x09/\1 /g' | tee -a $fichier_sortie
      fi # lister alpha
      deplus=""
      affichage_frequence
   fi # fin lister_i
}
# fin analyse par mots frequence-----fonction : verification-------------------------------
verification()
{
   echo -e "\n::: Vérification :::\n" | tee -a $fichier_sortie
   echo -e "$donnees_source$ligne_cmd_ori " | tee -a $fichier_sortie
   if [ $type == texte ]; then
      if [ "$supp_punct" == "1" ] ; then
         balance=$(($car_in_mots - $nb_total_insecables - $nb_chars_dans_car))
      else
         balance=$(($car_in_mots + $autres - $nb_total_insecables - $nb_chars_dans_car))
      fi
   else
      balance=$(($car_in_mots - $espaces - $nb_chars_dans_car))
   fi
   if [ $balance == 0 ] ;then
      echo "::: Les résultats des analyses par mots et par caractères correspondent" | tee -a $fichier_sortie
      echo "::: Les chiffres donnés peuvent être tenus pour justes (pour les arguments donnés)" | tee -a $fichier_sortie
   fi
   if [ $balance -lt 0 ] ;then
      echo "::: Les résultats des analyses par mots et par caractères ne correspondent pas ($balance)" | tee -a $fichier_sortie
      echo -e "::: Des éléments du fichier de données '"$objet"' ne sont pas connus du module d'analyse par mots ($balance)" | tee -a $fichier_sortie
   fi
   if [ $balance -gt 0 ] ;then
      echo "::: Les résultats des analyses par mots et par caractères ne correspondent pas ($balance)" | tee -a $fichier_sortie
      echo "::: Raison incertaine, merci de signaler ce cas" | tee -a $fichier_sortie
   fi
   echo "::: ----------------------------------------------------------------------------"
}
# fin verification-------------------fonction : mots2csv-----------------------------------
mots2csv()
{
   # un peu répétitif, mais clair et l'enchaînement des sed par pipe ne marche qu'en partie seulement
   donnees=$(sed -E -e 's/(^::: )(.*)/\2/g' <<< cat $fichier_sortie)
   donnees=$(sed -E -e 's/ ::: /;/g' <<< $donnees)
   donnees=$(sed -E -e 's/(.*)( => )(.*)/\1;"\3\"/g' <<< $donnees)
   if [ $analyse_chars -eq 1 ] ; then
      donnees=$(sed -E -e 's/(^[0-9]*;[0-9]*;)"(.?) soit [0-9.]*| %"/\1"\2/g' <<< $donnees)
   fi
   if [ $analyse_mots_detail -eq 1 ] ; then
      donnees=$(sed -E -e 's/(^[0-9]*;[0-9]*;)"([0-9]*) soit [0-9.]*|%"/\1\2/g' <<< $donnees)
   fi
   donnees=$(sed -E -e 's/(^[0-9]*;[0-9]*;)"([0-9]*)"$/\1\2/g' <<< $donnees)
   donnees=$(sed -E -e '/^[0-9]|^Rang|^Fr.quence|^Taille|^R.partition|^Nombre/!d' <<< $donnees)
   donnees=$(sed -E -e '/^Fr.quence|^Taille|^R.partition|^Nombre/{x;p;x}' <<< $donnees)
   donnees=$(sed -E -e 's/^Fr.quence .*|^Taille .*|^R.partition .*|^Nombre .*/&;;/g' <<< $donnees)
   echo -e "$donnees\n" > $fichier_sortie.csv
}
# fin mots2csv ----------------------fonction : mots2pdf-----------------------------------
mots2pdf()
{
   type enscript &>/dev/null && type ps2pdfwr &>/dev/null
   if [ $? == 0 ]; then
      # la "mauvaise" apostrophe fait planter iconv, donc la transforme. Les autres mauvais char sont supprimé par -c
      cat $fichier_sortie | sed -E -e "s/\’/\'/g" | enscript --output=- --filter="iconv -c -f utf-8 -t ISO-8859-15//TRANSLIT" \
          -B --margin=20:5:5:5: -f Helvetica@9/10 -j 2>/dev/null | ps2pdfwr - > $fichier_sortie.pdf
   fi
}
# fin mots2pdf ----------------------main--------------------------------------------------

preliminaire

analyse_par_mots_commun "$@"

# rappel : par defaut des trois options ci-dessous "analyse_mots_detail=1"
if [ "$analyse_mots_detail" == "1" ] ; then
   analyse_par_mots_detail "$@"
fi
if [ "$analyse_frequence" == "1" ] ; then
   analyse_par_mots_frequence "$@"
fi
if [ "$analyse_chars" == "1" ] ; then
   analyse_par_caracteres "$@"
fi
if [ "$verification" == "1" ] ; then
   verification "$@"
fi
if [ "$option_csv" == "1" ] ; then
   mots2csv "$@"
fi

postliminaire

exit 0
